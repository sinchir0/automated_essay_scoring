{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "SEED = 42\n",
    "N_FOLD = 3\n",
    "\n",
    "# path setting\n",
    "EXP_NAME = \"e-tfidf-wo-pca\"\n",
    "MODEL_NAME = \"tfidf\"\n",
    "COMPETITION_NAME = \"automated_essay_scoring\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME.split('/')[-1]}\"\n",
    "MODEL_OUTPUT_PATH = f\"trained_models/{EXP_NAME}\"\n",
    "\n",
    "UPLOAD_DATA_TO_KAGGLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataset_name(dataset_name: str) -> None:\n",
    "    if len(dataset_name) < 6 or len(dataset_name) > 50:\n",
    "        raise Exception(\n",
    "            f\"データセットの文字列は6~50文字にしてください。現在{len(DATASET_NAME)}文字\"\n",
    "        )\n",
    "    if \"_\" in dataset_name:\n",
    "        raise Exception(\"datasetの名称に_の使用は禁止です\")\n",
    "\n",
    "\n",
    "validate_dataset_name(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shinichiro.saito/automated_essay_scoring/automated_essay_scoring/eda\n",
      "Local Mac!\n",
      "../../data\n",
      "/Users/shinichiro.saito/automated_essay_scoring/automated_essay_scoring/eda\n",
      "Local Mac!\n",
      "../../trained_models/e-tfidf-wo-pca\n"
     ]
    }
   ],
   "source": [
    "def resolve_path(base_path: str) -> str:\n",
    "    import os\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    if cwd == f\"/notebooks\":\n",
    "        print(\"Jupyter Kernel By VSCode!\")\n",
    "        return f\"/notebooks/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}\":\n",
    "        print(\"nohup!\")\n",
    "        return base_path\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}/{COMPETITION_NAME}/exp\":\n",
    "        print(\"Jupyter Lab!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    elif cwd.startswith(\"/Users\"):\n",
    "        print(\"Local Mac!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment\")\n",
    "\n",
    "\n",
    "DATA_PATH = resolve_path(DATA_PATH)\n",
    "print(DATA_PATH)\n",
    "MODEL_OUTPUT_PATH = resolve_path(MODEL_OUTPUT_PATH)\n",
    "print(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the same seed to all\n",
    "def seed_everything(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(f\"{DATA_PATH}/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_PATH}/essay_id_fold_by_s_sl_g_p_only_train_dict.json\") as f:\n",
    "    essay_id_fold_only_train = json.load(f)\n",
    "\n",
    "train = train.with_columns(\n",
    "    pl.col(\"essay_id\")\n",
    "    .replace(essay_id_fold_only_train, return_dtype=pl.Int64)\n",
    "    .alias(\"fold\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_id</th><th>full_text</th><th>score</th><th>fold</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;000d118&quot;</td><td>&quot;Many people have car where the…</td><td>3</td><td>0</td></tr><tr><td>&quot;000fe60&quot;</td><td>&quot;I am a scientist at NASA that …</td><td>3</td><td>0</td></tr><tr><td>&quot;001ab80&quot;</td><td>&quot;People always wish they had th…</td><td>4</td><td>1</td></tr><tr><td>&quot;001bdc0&quot;</td><td>&quot;We all heard about Venus, the …</td><td>4</td><td>0</td></tr><tr><td>&quot;002ba53&quot;</td><td>&quot;Dear, State Senator\n",
       "\n",
       "This is a…</td><td>3</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌──────────┬─────────────────────────────────┬───────┬──────┐\n",
       "│ essay_id ┆ full_text                       ┆ score ┆ fold │\n",
       "│ ---      ┆ ---                             ┆ ---   ┆ ---  │\n",
       "│ str      ┆ str                             ┆ i64   ┆ i64  │\n",
       "╞══════════╪═════════════════════════════════╪═══════╪══════╡\n",
       "│ 000d118  ┆ Many people have car where the… ┆ 3     ┆ 0    │\n",
       "│ 000fe60  ┆ I am a scientist at NASA that … ┆ 3     ┆ 0    │\n",
       "│ 001ab80  ┆ People always wish they had th… ┆ 4     ┆ 1    │\n",
       "│ 001bdc0  ┆ We all heard about Venus, the … ┆ 4     ┆ 0    │\n",
       "│ 002ba53  ┆ Dear, State Senator             ┆ 3     ┆ 2    │\n",
       "│          ┆                                 ┆       ┆      │\n",
       "│          ┆ This is a…                      ┆       ┆      │\n",
       "└──────────┴─────────────────────────────────┴───────┴──────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    strip_accents=\"unicode\",\n",
    "    analyzer=\"word\",\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=0.05,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "vectorizer.fit(train[\"full_text\"])\n",
    "all_voc = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1203"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fold 0\n",
      "Start fold 1\n",
      "Start fold 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "\n",
    "\n",
    "oofs: list[pd.DataFrame] = []\n",
    "# Cross Validationによる学習の実施\n",
    "for fold in range(N_FOLD):\n",
    "    print(f\"Start fold {fold}\")\n",
    "\n",
    "    # foldごとにtrainとvalidに分ける\n",
    "    train_fold = train.filter(pl.col(\"fold\") != fold)\n",
    "    valid_fold = train.filter(pl.col(\"fold\") == fold)\n",
    "\n",
    "    # TfidfVectorizer parameter\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        strip_accents=\"unicode\",\n",
    "        analyzer=\"word\",\n",
    "        ngram_range=(1, 3),\n",
    "        min_df=0.05,\n",
    "        max_df=0.95,\n",
    "        sublinear_tf=True,\n",
    "        vocabulary=all_voc,\n",
    "    )\n",
    "\n",
    "    vectorizer.fit(train_fold[\"full_text\"])\n",
    "    valid_tfid = vectorizer.transform(valid_fold[\"full_text\"])\n",
    "\n",
    "    dense_matrix = valid_tfid.toarray()\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        dense_matrix,\n",
    "        columns=[f\"tfidf_{i}\" for i in range(len(all_voc))],\n",
    "    )\n",
    "\n",
    "    df[\"essay_id\"] = valid_fold[\"essay_id\"]\n",
    "\n",
    "    oofs.append(df)\n",
    "\n",
    "    # save vectorizer\n",
    "    with open(\n",
    "        f\"{MODEL_OUTPUT_PATH}/tfidf_vectorizer_s_sl_g_p_fold{fold}.pkl\", \"wb\"\n",
    "    ) as file:\n",
    "        pickle.dump(vectorizer, file)\n",
    "\n",
    "all_tfidf_res = pd.concat(oofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_tfidf = pd.DataFrame(\n",
    "#     all_tfidf_res,\n",
    "#     columns=[f\"tfidf_{i}\" for i in range(100)],\n",
    "# )\n",
    "# oof_tfidf[\"essay_id\"] = all_tfidf_res[\"essay_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_0</th>\n",
       "      <th>tfidf_1</th>\n",
       "      <th>tfidf_2</th>\n",
       "      <th>tfidf_3</th>\n",
       "      <th>tfidf_4</th>\n",
       "      <th>tfidf_5</th>\n",
       "      <th>tfidf_6</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_8</th>\n",
       "      <th>tfidf_9</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_1194</th>\n",
       "      <th>tfidf_1195</th>\n",
       "      <th>tfidf_1196</th>\n",
       "      <th>tfidf_1197</th>\n",
       "      <th>tfidf_1198</th>\n",
       "      <th>tfidf_1199</th>\n",
       "      <th>tfidf_1200</th>\n",
       "      <th>tfidf_1201</th>\n",
       "      <th>tfidf_1202</th>\n",
       "      <th>essay_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031682</td>\n",
       "      <td>000d118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069853</td>\n",
       "      <td>0.081853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>000fe60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150417</td>\n",
       "      <td>0.161345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>001bdc0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0036253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0047cb3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tfidf_0  tfidf_1   tfidf_2   tfidf_3  tfidf_4  tfidf_5   tfidf_6  tfidf_7  \\\n",
       "0      0.0      0.0  0.000000  0.000000      0.0      0.0  0.000000      0.0   \n",
       "1      0.0      0.0  0.000000  0.000000      0.0      0.0  0.000000      0.0   \n",
       "2      0.0      0.0  0.150417  0.161345      0.0      0.0  0.095293      0.0   \n",
       "3      0.0      0.0  0.000000  0.000000      0.0      0.0  0.000000      0.0   \n",
       "4      0.0      0.0  0.000000  0.000000      0.0      0.0  0.000000      0.0   \n",
       "\n",
       "   tfidf_8   tfidf_9  ...  tfidf_1194  tfidf_1195  tfidf_1196  tfidf_1197  \\\n",
       "0      0.0  0.029255  ...         0.0         0.0    0.000000    0.000000   \n",
       "1      0.0  0.035858  ...         0.0         0.0    0.069853    0.081853   \n",
       "2      0.0  0.032677  ...         0.0         0.0    0.000000    0.000000   \n",
       "3      0.0  0.038582  ...         0.0         0.0    0.000000    0.000000   \n",
       "4      0.0  0.000000  ...         0.0         0.0    0.000000    0.000000   \n",
       "\n",
       "   tfidf_1198  tfidf_1199  tfidf_1200  tfidf_1201  tfidf_1202  essay_id  \n",
       "0         0.0         0.0         0.0         0.0    0.031682   000d118  \n",
       "1         0.0         0.0         0.0         0.0    0.000000   000fe60  \n",
       "2         0.0         0.0         0.0         0.0    0.000000   001bdc0  \n",
       "3         0.0         0.0         0.0         0.0    0.000000   0036253  \n",
       "4         0.0         0.0         0.0         0.0    0.000000   0047cb3  \n",
       "\n",
       "[5 rows x 1204 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tfidf_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tfidf_res.to_csv(f\"{MODEL_OUTPUT_PATH}/oof_tfidf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggleへのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataset name:e-tfidf-wo-pca-tfidf, output_dir:../../trained_models/e-tfidf-wo-pca\n",
      "Starting upload for file tfidf_vectorizer_s_sl_g_p_fold2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43.5k/43.5k [00:00<00:00, 58.2kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: tfidf_vectorizer_s_sl_g_p_fold2.pkl (43KB)\n",
      "Starting upload for file tfidf_vectorizer_s_sl_g_p_fold0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43.5k/43.5k [00:00<00:00, 58.8kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: tfidf_vectorizer_s_sl_g_p_fold0.pkl (43KB)\n",
      "Starting upload for file tfidf_vectorizer_s_sl_g_p_fold1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43.5k/43.5k [00:00<00:00, 57.5kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: tfidf_vectorizer_s_sl_g_p_fold1.pkl (43KB)\n",
      "Starting upload for file oof_tfidf.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122M/122M [00:10<00:00, 12.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: oof_tfidf.csv (122MB)\n"
     ]
    }
   ],
   "source": [
    "if UPLOAD_DATA_TO_KAGGLE:\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "        # if \"_\" in dataset_name:\n",
    "        #     raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "        dataset_metadata = {}\n",
    "        dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "        dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "        dataset_metadata[\"title\"] = dataset_name\n",
    "        with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=4)\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "    print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{MODEL_OUTPUT_PATH}\")\n",
    "    dataset_create_new(dataset_name=DATASET_NAME, upload_dir=MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
