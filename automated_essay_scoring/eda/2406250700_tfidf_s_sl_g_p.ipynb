{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "SEED = 42\n",
    "N_FOLD = 3\n",
    "\n",
    "# path setting\n",
    "EXP_NAME = \"e-tfidf\"\n",
    "MODEL_NAME = \"tfidf\"\n",
    "COMPETITION_NAME = \"automated_essay_scoring\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME.split('/')[-1]}\"\n",
    "MODEL_OUTPUT_PATH = f\"trained_models/{EXP_NAME}\"\n",
    "\n",
    "UPLOAD_DATA_TO_KAGGLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataset_name(dataset_name: str) -> None:\n",
    "    if len(dataset_name) < 6 or len(dataset_name) > 50:\n",
    "        raise Exception(\n",
    "            f\"データセットの文字列は6~50文字にしてください。現在{len(DATASET_NAME)}文字\"\n",
    "        )\n",
    "    if \"_\" in dataset_name:\n",
    "        raise Exception(\"datasetの名称に_の使用は禁止です\")\n",
    "\n",
    "\n",
    "validate_dataset_name(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shinichiro.saito/automated_essay_scoring/automated_essay_scoring/eda\n",
      "Local Mac!\n",
      "../../data\n",
      "/Users/shinichiro.saito/automated_essay_scoring/automated_essay_scoring/eda\n",
      "Local Mac!\n",
      "../../trained_models/e-tfidf\n"
     ]
    }
   ],
   "source": [
    "def resolve_path(base_path: str) -> str:\n",
    "    import os\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    if cwd == f\"/notebooks\":\n",
    "        print(\"Jupyter Kernel By VSCode!\")\n",
    "        return f\"/notebooks/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}\":\n",
    "        print(\"nohup!\")\n",
    "        return base_path\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}/{COMPETITION_NAME}/exp\":\n",
    "        print(\"Jupyter Lab!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    elif cwd.startswith(\"/Users\"):\n",
    "        print(\"Local Mac!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment\")\n",
    "\n",
    "\n",
    "DATA_PATH = resolve_path(DATA_PATH)\n",
    "print(DATA_PATH)\n",
    "MODEL_OUTPUT_PATH = resolve_path(MODEL_OUTPUT_PATH)\n",
    "print(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the same seed to all\n",
    "def seed_everything(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(f\"{DATA_PATH}/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_PATH}/essay_id_fold_by_s_sl_g_p_only_train_dict.json\") as f:\n",
    "    essay_id_fold_only_train = json.load(f)\n",
    "\n",
    "train = train.with_columns(\n",
    "    pl.col(\"essay_id\")\n",
    "    .replace(essay_id_fold_only_train, return_dtype=pl.Int64)\n",
    "    .alias(\"fold\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_id</th><th>full_text</th><th>score</th><th>fold</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;000d118&quot;</td><td>&quot;Many people have car where the…</td><td>3</td><td>0</td></tr><tr><td>&quot;000fe60&quot;</td><td>&quot;I am a scientist at NASA that …</td><td>3</td><td>0</td></tr><tr><td>&quot;001ab80&quot;</td><td>&quot;People always wish they had th…</td><td>4</td><td>1</td></tr><tr><td>&quot;001bdc0&quot;</td><td>&quot;We all heard about Venus, the …</td><td>4</td><td>0</td></tr><tr><td>&quot;002ba53&quot;</td><td>&quot;Dear, State Senator\n",
       "\n",
       "This is a…</td><td>3</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌──────────┬─────────────────────────────────┬───────┬──────┐\n",
       "│ essay_id ┆ full_text                       ┆ score ┆ fold │\n",
       "│ ---      ┆ ---                             ┆ ---   ┆ ---  │\n",
       "│ str      ┆ str                             ┆ i64   ┆ i64  │\n",
       "╞══════════╪═════════════════════════════════╪═══════╪══════╡\n",
       "│ 000d118  ┆ Many people have car where the… ┆ 3     ┆ 0    │\n",
       "│ 000fe60  ┆ I am a scientist at NASA that … ┆ 3     ┆ 0    │\n",
       "│ 001ab80  ┆ People always wish they had th… ┆ 4     ┆ 1    │\n",
       "│ 001bdc0  ┆ We all heard about Venus, the … ┆ 4     ┆ 0    │\n",
       "│ 002ba53  ┆ Dear, State Senator             ┆ 3     ┆ 2    │\n",
       "│          ┆                                 ┆       ┆      │\n",
       "│          ┆ This is a…                      ┆       ┆      │\n",
       "└──────────┴─────────────────────────────────┴───────┴──────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    strip_accents=\"unicode\",\n",
    "    analyzer=\"word\",\n",
    "    ngram_range=(3, 6),\n",
    "    min_df=0.05,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "vectorizer.fit(train[\"full_text\"])\n",
    "all_voc = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fold 0\n",
      "Start fold 1\n",
      "Start fold 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "\n",
    "\n",
    "oofs: list[pd.DataFrame] = []\n",
    "# Cross Validationによる学習の実施\n",
    "for fold in range(N_FOLD):\n",
    "    print(f\"Start fold {fold}\")\n",
    "\n",
    "    # foldごとにtrainとvalidに分ける\n",
    "    train_fold = train.filter(pl.col(\"fold\") != fold)\n",
    "    valid_fold = train.filter(pl.col(\"fold\") == fold)\n",
    "\n",
    "    # TfidfVectorizer parameter\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        strip_accents=\"unicode\",\n",
    "        analyzer=\"word\",\n",
    "        ngram_range=(1, 3),\n",
    "        min_df=0.05,\n",
    "        max_df=0.95,\n",
    "        sublinear_tf=True,\n",
    "        vocabulary=all_voc,\n",
    "    )\n",
    "\n",
    "    vectorizer.fit(train_fold[\"full_text\"])\n",
    "    valid_tfid = vectorizer.transform(valid_fold[\"full_text\"])\n",
    "\n",
    "    dense_matrix = valid_tfid.toarray()\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        dense_matrix,\n",
    "        columns=[f\"tfidf_{i}\" for i in range(len(all_voc))],\n",
    "    )\n",
    "\n",
    "    df[\"essay_id\"] = valid_fold[\"essay_id\"]\n",
    "\n",
    "    oofs.append(df)\n",
    "\n",
    "    # save vectorizer\n",
    "    with open(\n",
    "        f\"{MODEL_OUTPUT_PATH}/tfidf_vectorizer_s_sl_g_p_fold{fold}.pkl\", \"wb\"\n",
    "    ) as file:\n",
    "        pickle.dump(vectorizer, file)\n",
    "\n",
    "all_tfidf_res = pd.concat(oofs)\n",
    "pca = PCA(n_components=100)\n",
    "all_tfidf_reduced = pca.fit_transform(\n",
    "    all_tfidf_res[[f\"tfidf_{i}\" for i in range(len(all_voc))]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_tfidf = pd.DataFrame(\n",
    "    all_tfidf_reduced,\n",
    "    columns=[f\"tfidf_{i}\" for i in range(100)],\n",
    ")\n",
    "oof_tfidf[\"essay_id\"] = all_tfidf_res[\"essay_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_0</th>\n",
       "      <th>tfidf_1</th>\n",
       "      <th>tfidf_2</th>\n",
       "      <th>tfidf_3</th>\n",
       "      <th>tfidf_4</th>\n",
       "      <th>tfidf_5</th>\n",
       "      <th>tfidf_6</th>\n",
       "      <th>tfidf_7</th>\n",
       "      <th>tfidf_8</th>\n",
       "      <th>tfidf_9</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_91</th>\n",
       "      <th>tfidf_92</th>\n",
       "      <th>tfidf_93</th>\n",
       "      <th>tfidf_94</th>\n",
       "      <th>tfidf_95</th>\n",
       "      <th>tfidf_96</th>\n",
       "      <th>tfidf_97</th>\n",
       "      <th>tfidf_98</th>\n",
       "      <th>tfidf_99</th>\n",
       "      <th>essay_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071303</td>\n",
       "      <td>-0.025168</td>\n",
       "      <td>0.026312</td>\n",
       "      <td>0.007992</td>\n",
       "      <td>0.144536</td>\n",
       "      <td>0.282579</td>\n",
       "      <td>-0.068989</td>\n",
       "      <td>-0.116552</td>\n",
       "      <td>-0.100728</td>\n",
       "      <td>-0.024354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046455</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.014329</td>\n",
       "      <td>-0.029865</td>\n",
       "      <td>-0.013112</td>\n",
       "      <td>0.014016</td>\n",
       "      <td>-0.037306</td>\n",
       "      <td>-0.032094</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>000d118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.213989</td>\n",
       "      <td>-0.098673</td>\n",
       "      <td>0.163686</td>\n",
       "      <td>0.542009</td>\n",
       "      <td>-0.137247</td>\n",
       "      <td>-0.045957</td>\n",
       "      <td>-0.005828</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>-0.020199</td>\n",
       "      <td>-0.030830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031225</td>\n",
       "      <td>0.022761</td>\n",
       "      <td>-0.009540</td>\n",
       "      <td>-0.051266</td>\n",
       "      <td>-0.026955</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>0.019717</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>-0.064898</td>\n",
       "      <td>000fe60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.462950</td>\n",
       "      <td>-0.268511</td>\n",
       "      <td>-0.285860</td>\n",
       "      <td>-0.171814</td>\n",
       "      <td>-0.050769</td>\n",
       "      <td>-0.026806</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.015919</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>-0.016290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001518</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.021521</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>-0.031396</td>\n",
       "      <td>-0.034834</td>\n",
       "      <td>-0.042466</td>\n",
       "      <td>001bdc0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.474875</td>\n",
       "      <td>-0.268998</td>\n",
       "      <td>-0.308659</td>\n",
       "      <td>-0.218077</td>\n",
       "      <td>-0.056140</td>\n",
       "      <td>-0.064449</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>0.049717</td>\n",
       "      <td>0.108840</td>\n",
       "      <td>0.115138</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004571</td>\n",
       "      <td>-0.047324</td>\n",
       "      <td>-0.013683</td>\n",
       "      <td>-0.017371</td>\n",
       "      <td>0.047397</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.043167</td>\n",
       "      <td>-0.007941</td>\n",
       "      <td>-0.020170</td>\n",
       "      <td>0036253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060296</td>\n",
       "      <td>-0.026000</td>\n",
       "      <td>0.037222</td>\n",
       "      <td>0.010112</td>\n",
       "      <td>0.182746</td>\n",
       "      <td>0.572020</td>\n",
       "      <td>0.067592</td>\n",
       "      <td>0.079728</td>\n",
       "      <td>0.061420</td>\n",
       "      <td>0.027516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.022420</td>\n",
       "      <td>-0.009882</td>\n",
       "      <td>-0.013467</td>\n",
       "      <td>0.033988</td>\n",
       "      <td>-0.031986</td>\n",
       "      <td>0.017821</td>\n",
       "      <td>-0.005743</td>\n",
       "      <td>0.024899</td>\n",
       "      <td>0047cb3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tfidf_0   tfidf_1   tfidf_2   tfidf_3   tfidf_4   tfidf_5   tfidf_6  \\\n",
       "0  0.071303 -0.025168  0.026312  0.007992  0.144536  0.282579 -0.068989   \n",
       "1 -0.213989 -0.098673  0.163686  0.542009 -0.137247 -0.045957 -0.005828   \n",
       "2 -0.462950 -0.268511 -0.285860 -0.171814 -0.050769 -0.026806  0.017007   \n",
       "3 -0.474875 -0.268998 -0.308659 -0.218077 -0.056140 -0.064449  0.035620   \n",
       "4  0.060296 -0.026000  0.037222  0.010112  0.182746  0.572020  0.067592   \n",
       "\n",
       "    tfidf_7   tfidf_8   tfidf_9  ...  tfidf_91  tfidf_92  tfidf_93  tfidf_94  \\\n",
       "0 -0.116552 -0.100728 -0.024354  ...  0.046455  0.007930  0.014329 -0.029865   \n",
       "1 -0.009804 -0.020199 -0.030830  ...  0.031225  0.022761 -0.009540 -0.051266   \n",
       "2  0.015919  0.007950 -0.016290  ... -0.001518  0.006182 -0.000406  0.021521   \n",
       "3  0.049717  0.108840  0.115138  ... -0.004571 -0.047324 -0.013683 -0.017371   \n",
       "4  0.079728  0.061420  0.027516  ...  0.001411  0.022420 -0.009882 -0.013467   \n",
       "\n",
       "   tfidf_95  tfidf_96  tfidf_97  tfidf_98  tfidf_99  essay_id  \n",
       "0 -0.013112  0.014016 -0.037306 -0.032094  0.001985   000d118  \n",
       "1 -0.026955  0.012087  0.019717  0.019481 -0.064898   000fe60  \n",
       "2  0.010319  0.002140 -0.031396 -0.034834 -0.042466   001bdc0  \n",
       "3  0.047397  0.002733  0.043167 -0.007941 -0.020170   0036253  \n",
       "4  0.033988 -0.031986  0.017821 -0.005743  0.024899   0047cb3  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_tfidf.to_csv(f\"{MODEL_OUTPUT_PATH}/oof_tfidf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggleへのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataset name:e-tfidf-tfidf, output_dir:../../trained_models/e-tfidf\n",
      "Starting upload for file tfidf_vectorizer_s_sl_g_p_fold2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43.5k/43.5k [00:00<00:00, 57.1kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: tfidf_vectorizer_s_sl_g_p_fold2.pkl (43KB)\n",
      "Starting upload for file tfidf_vectorizer_s_sl_g_p_fold0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43.5k/43.5k [00:00<00:00, 56.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: tfidf_vectorizer_s_sl_g_p_fold0.pkl (43KB)\n",
      "Starting upload for file tfidf_vectorizer_s_sl_g_p_fold1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43.5k/43.5k [00:00<00:00, 58.6kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: tfidf_vectorizer_s_sl_g_p_fold1.pkl (43KB)\n",
      "Starting upload for file oof_tfidf.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35.0M/35.0M [00:02<00:00, 12.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: oof_tfidf.csv (35MB)\n"
     ]
    }
   ],
   "source": [
    "if UPLOAD_DATA_TO_KAGGLE:\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "        # if \"_\" in dataset_name:\n",
    "        #     raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "        dataset_metadata = {}\n",
    "        dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "        dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "        dataset_metadata[\"title\"] = dataset_name\n",
    "        with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=4)\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "    print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{MODEL_OUTPUT_PATH}\")\n",
    "    dataset_create_new(dataset_name=DATASET_NAME, upload_dir=MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
