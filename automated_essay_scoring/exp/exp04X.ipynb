{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  目的\n",
    "cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:08.317539Z",
     "iopub.status.busy": "2024-05-25T10:37:08.317358Z",
     "iopub.status.idle": "2024-05-25T10:37:08.324885Z",
     "shell.execute_reply": "2024-05-25T10:37:08.324243Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path setting\n",
    "EXP_NAME = \"e048-cross-validation\"\n",
    "MODEL_NAME = \"microsoft/deberta-v3-xsmall\"\n",
    "COMPETITION_NAME = \"automated_essay_scoring\"\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME.split('/')[-1]}\"\n",
    "MODEL_OUTPUT_PATH = f\"trained_models/{EXP_NAME}\"\n",
    "\n",
    "# experiment parameter\n",
    "DEBUG = True\n",
    "TRAINING = True\n",
    "UPLOAD_DATA_TO_S3 = False\n",
    "UPLOAD_DATA_TO_KAGGLE = False\n",
    "WANDB = False\n",
    "\n",
    "NUM_FOLD = 3\n",
    "\n",
    "# model parameter\n",
    "# TRAINING_MAX_LENGTH= 512\n",
    "TRAINING_MAX_LENGTH = 1024\n",
    "INFERENCE_MAX_LENGTH = 1536\n",
    "SEED = 42\n",
    "EPOCH = 4\n",
    "LR = 2e-05\n",
    "TRAIN_BS = 8\n",
    "GRAD_ACC_NUM = 16\n",
    "EVAL_BS = 8\n",
    "SAVE_STEP = 0.1\n",
    "EVAL_STEP = 0.1\n",
    "LR_SCHE_TYPE = \"linear\"\n",
    "\n",
    "# TRAINED_MODEL_PATH = (\n",
    "#     \"/notebooks/\" + \"automated_essay_scoring/trained_models/e016-not-use-dropout\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:08.327860Z",
     "iopub.status.busy": "2024-05-25T10:37:08.327264Z",
     "iopub.status.idle": "2024-05-25T10:37:08.741877Z",
     "shell.execute_reply": "2024-05-25T10:37:08.741064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 17 23:00:07 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   34C    P8    27W / 300W |      1MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:08.744939Z",
     "iopub.status.busy": "2024-05-25T10:37:08.744746Z",
     "iopub.status.idle": "2024-05-25T10:37:08.857535Z",
     "shell.execute_reply": "2024-05-25T10:37:08.856730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:08.861034Z",
     "iopub.status.busy": "2024-05-25T10:37:08.860814Z",
     "iopub.status.idle": "2024-05-25T10:37:08.865843Z",
     "shell.execute_reply": "2024-05-25T10:37:08.865301Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\n",
      "Jupyter Kernel By VSCode!\n",
      "/notebooks/automated_essay_scoring/data\n",
      "/notebooks\n",
      "Jupyter Kernel By VSCode!\n",
      "/notebooks/automated_essay_scoring/trained_models/e048-cross-validation\n"
     ]
    }
   ],
   "source": [
    "def resolve_path(base_path: str) -> str:\n",
    "    import os\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    if cwd == f\"/notebooks\":\n",
    "        print(\"Jupyter Kernel By VSCode!\")\n",
    "        return f\"/notebooks/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}\":\n",
    "        print(\"nohup!\")\n",
    "        return base_path\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}/{COMPETITION_NAME}/exp\":\n",
    "        print(\"Jupyter Lab!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    elif cwd.startswith(\"/Users/\"):\n",
    "        print(\"Local VSCode!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment\")\n",
    "\n",
    "\n",
    "DATA_PATH = resolve_path(DATA_PATH)\n",
    "print(DATA_PATH)\n",
    "MODEL_OUTPUT_PATH = resolve_path(MODEL_OUTPUT_PATH)\n",
    "print(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:08.868251Z",
     "iopub.status.busy": "2024-05-25T10:37:08.867836Z",
     "iopub.status.idle": "2024-05-25T10:37:08.871076Z",
     "shell.execute_reply": "2024-05-25T10:37:08.870554Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate_dataset_name(dataset_name: str) -> None:\n",
    "    if len(dataset_name) < 6 or len(dataset_name) > 50:\n",
    "        raise Exception(\n",
    "            f\"データセットの文字列は6~50文字にしてください。現在{len(DATASET_NAME)}文字\"\n",
    "        )\n",
    "    if \"_\" in dataset_name:\n",
    "        raise Exception(\"datasetの名称に_の使用は禁止です\")\n",
    "\n",
    "\n",
    "validate_dataset_name(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:08.872721Z",
     "iopub.status.busy": "2024-05-25T10:37:08.872567Z",
     "iopub.status.idle": "2024-05-25T10:37:34.015732Z",
     "shell.execute_reply": "2024-05-25T10:37:34.015031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq polars==0.20.23\n",
    "%pip install -qq transformers==4.40.1\n",
    "%pip install -qq datasets==2.19.0\n",
    "%pip install -qq evaluate==0.4.2\n",
    "%pip install -qq seqeval==1.2.2\n",
    "%pip install -qq accelerate==0.30.0\n",
    "%pip install -qq python-dotenv==1.0.1\n",
    "%pip install -qq wandb==0.16.6\n",
    "\n",
    "# formatter\n",
    "%pip install -qq black isort\n",
    "\n",
    "%pip install -qq kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:34.018552Z",
     "iopub.status.busy": "2024-05-25T10:37:34.017888Z",
     "iopub.status.idle": "2024-05-25T10:37:41.522459Z",
     "shell.execute_reply": "2024-05-25T10:37:41.521762Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "import wandb\n",
    "from datasets import DatasetDict, Value, concatenate_datasets, load_dataset\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tokenizers import AddedToken\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    DebertaV2PreTrainedModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import (\n",
    "    ContextPooler,\n",
    "    StableDropout,\n",
    "    DebertaV2Model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:41.525305Z",
     "iopub.status.busy": "2024-05-25T10:37:41.524563Z",
     "iopub.status.idle": "2024-05-25T10:37:41.528449Z",
     "shell.execute_reply": "2024-05-25T10:37:41.527983Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOKENIZERS_PARALLELISM\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m NUM_PROC \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mcpu_count()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "NUM_PROC = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:41.530195Z",
     "iopub.status.busy": "2024-05-25T10:37:41.530057Z",
     "iopub.status.idle": "2024-05-25T10:37:41.567956Z",
     "shell.execute_reply": "2024-05-25T10:37:41.567376Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "assert transformers.__version__ == \"4.40.1\"\n",
    "assert datasets.__version__ == \"2.19.0\"\n",
    "assert evaluate.__version__ == \"0.4.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:41.570451Z",
     "iopub.status.busy": "2024-05-25T10:37:41.569945Z",
     "iopub.status.idle": "2024-05-25T10:37:41.573939Z",
     "shell.execute_reply": "2024-05-25T10:37:41.573501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seed the same seed to all\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:41.575644Z",
     "iopub.status.busy": "2024-05-25T10:37:41.575477Z",
     "iopub.status.idle": "2024-05-25T10:37:41.591317Z",
     "shell.execute_reply": "2024-05-25T10:37:41.590813Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(f\"{DATA_PATH}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:41.612926Z",
     "iopub.status.busy": "2024-05-25T10:37:41.612233Z",
     "iopub.status.idle": "2024-05-25T10:37:43.241348Z",
     "shell.execute_reply": "2024-05-25T10:37:43.240969Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'none'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "    wandb.init(project=\"automated_essay_scoring\", name=EXP_NAME)\n",
    "    REPORT_TO = \"wandb\"\n",
    "else:\n",
    "    REPORT_TO = \"none\"\n",
    "\n",
    "REPORT_TO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:43.243408Z",
     "iopub.status.busy": "2024-05-25T10:37:43.243049Z",
     "iopub.status.idle": "2024-05-25T10:37:43.385716Z",
     "shell.execute_reply": "2024-05-25T10:37:43.385124Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['essay_id', 'full_text', 'score', 'flag'],\n",
       "    num_rows: 17307\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=f\"{DATA_PATH}/train.csv\",\n",
    "    split=\"train\",\n",
    ").map(lambda example: {\"flag\": \"original\"})\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:43.388599Z",
     "iopub.status.busy": "2024-05-25T10:37:43.388048Z",
     "iopub.status.idle": "2024-05-25T10:37:43.563754Z",
     "shell.execute_reply": "2024-05-25T10:37:43.563217Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['essay_id', 'full_text', 'score', 'flag'],\n",
       "    num_rows: 13125\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 追加データ\n",
    "persuade_dataset = (\n",
    "    load_dataset(\n",
    "        \"csv\",\n",
    "        data_files={\"train\": f\"{DATA_PATH}/persuade_w_is_tr_con_as_num.csv\"},\n",
    "        split=\"train\",\n",
    "    )\n",
    "    .filter(lambda x: not x[\"is_train_contains\"], num_proc=NUM_PROC)\n",
    "    .select_columns([\"essay_id_comp\", \"full_text\", \"holistic_essay_score\"])\n",
    "    .rename_columns({\"essay_id_comp\": \"essay_id\", \"holistic_essay_score\": \"score\"})\n",
    "    .map(lambda example: {\"flag\": \"persuade\"})\n",
    ")\n",
    "\n",
    "persuade_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:43.565674Z",
     "iopub.status.busy": "2024-05-25T10:37:43.565458Z",
     "iopub.status.idle": "2024-05-25T10:37:43.567854Z",
     "shell.execute_reply": "2024-05-25T10:37:43.567433Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# データの結合\n",
    "train_dataset = concatenate_datasets([train_dataset, persuade_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:43.569398Z",
     "iopub.status.busy": "2024-05-25T10:37:43.569248Z",
     "iopub.status.idle": "2024-05-25T10:37:43.572068Z",
     "shell.execute_reply": "2024-05-25T10:37:43.571539Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train_dataset = train_dataset.shuffle(seed=SEED)\n",
    "    train_dataset = train_dataset.select(range(100))\n",
    "    EPOCH = 1\n",
    "    SAVE_STEP = 0.5\n",
    "    EVAL_STEP = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:43.573702Z",
     "iopub.status.busy": "2024-05-25T10:37:43.573553Z",
     "iopub.status.idle": "2024-05-25T10:37:44.408597Z",
     "shell.execute_reply": "2024-05-25T10:37:44.408143Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shinichiro.saito/automated_essay_scoring/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/shinichiro.saito/automated_essay_scoring/.venv/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.add_tokens(AddedToken(\"\\n\", normalized=False))\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:44.410703Z",
     "iopub.status.busy": "2024-05-25T10:37:44.410531Z",
     "iopub.status.idle": "2024-05-25T10:37:44.442373Z",
     "shell.execute_reply": "2024-05-25T10:37:44.441836Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples, max_token_length: int):\n",
    "    return tokenizer(\n",
    "        examples[\"full_text\"],\n",
    "        max_length=max_token_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    fn_kwargs={\"max_token_length\": TRAINING_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:44.445250Z",
     "iopub.status.busy": "2024-05-25T10:37:44.444843Z",
     "iopub.status.idle": "2024-05-25T10:37:44.452044Z",
     "shell.execute_reply": "2024-05-25T10:37:44.451467Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column(\"score\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:44.454384Z",
     "iopub.status.busy": "2024-05-25T10:37:44.453824Z",
     "iopub.status.idle": "2024-05-25T10:37:44.463714Z",
     "shell.execute_reply": "2024-05-25T10:37:44.463255Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_dataset[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:44.465359Z",
     "iopub.status.busy": "2024-05-25T10:37:44.465203Z",
     "iopub.status.idle": "2024-05-25T10:37:44.471077Z",
     "shell.execute_reply": "2024-05-25T10:37:44.470439Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"{DATA_PATH}/essay_id_fold_dict.json\") as f:\n",
    "    essay_id_fold_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:44.473023Z",
     "iopub.status.busy": "2024-05-25T10:37:44.472504Z",
     "iopub.status.idle": "2024-05-25T10:37:44.476047Z",
     "shell.execute_reply": "2024-05-25T10:37:44.475573Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['essay_id', 'full_text', 'labels', 'flag', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:44.477961Z",
     "iopub.status.busy": "2024-05-25T10:37:44.477461Z",
     "iopub.status.idle": "2024-05-25T10:37:44.855056Z",
     "shell.execute_reply": "2024-05-25T10:37:44.854432Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 外部データなし\n",
    "# def get_train_test_split_dataset(train_dataset):\n",
    "#     train_dataset = train_dataset.map(\n",
    "#         lambda x: {\"fold\": essay_id_fold_dict[x[\"essay_id\"]]}, num_proc=NUM_PROC\n",
    "#     )\n",
    "\n",
    "#     return DatasetDict(\n",
    "#         {\n",
    "#             \"train\": train_dataset.filter(lambda x: x[\"fold\"] != 2, num_proc=NUM_PROC),\n",
    "#             \"valid\": train_dataset.filter(lambda x: x[\"fold\"] == 2, num_proc=NUM_PROC),\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "\n",
    "# train_test_split_dataset = get_train_test_split_dataset(train_dataset)\n",
    "\n",
    "\n",
    "# # 外部データあり\n",
    "# # def get_train_test_split_dataset_w_external(train_dataset):\n",
    "# #     original_dataset = train_dataset.filter(\n",
    "# #         lambda x: x[\"flag\"] == \"original\", num_proc=NUM_PROC\n",
    "# #     )\n",
    "\n",
    "# #     external_train_dataset = train_dataset.filter(\n",
    "# #         lambda x: x[\"flag\"] != \"original\", num_proc=NUM_PROC\n",
    "# #     )\n",
    "\n",
    "# #     original_dataset = original_dataset.map(\n",
    "# #         lambda x: {\"fold\": essay_id_fold_dict[x[\"essay_id\"]]}, num_proc=NUM_PROC\n",
    "# #     )\n",
    "\n",
    "# #     original_train_dataset = original_dataset.filter(\n",
    "# #         lambda x: x[\"fold\"] != 2, num_proc=NUM_PROC\n",
    "# #     )\n",
    "# #     original_valid_dataset = original_dataset.filter(\n",
    "# #         lambda x: x[\"fold\"] == 2, num_proc=NUM_PROC\n",
    "# #     )\n",
    "\n",
    "# #     train_test_split_dataset = DatasetDict(\n",
    "# #         {\n",
    "# #             \"train\": concatenate_datasets(\n",
    "# #                 [original_train_dataset, external_train_dataset]\n",
    "# #             ),\n",
    "# #             \"valid\": original_valid_dataset,\n",
    "# #         }\n",
    "# #     )\n",
    "\n",
    "# #     return train_test_split_dataset\n",
    "\n",
    "\n",
    "# # train_test_split_dataset = get_train_test_split_dataset_w_external(train_dataset)\n",
    "\n",
    "# # Check\n",
    "# # assert set(train_test_split_dataset[\"train\"][\"fold\"]) == {0, 1}\n",
    "# assert set(train_test_split_dataset[\"valid\"][\"fold\"]) == {2}\n",
    "\n",
    "# if not DEBUG:\n",
    "#     essay_id_fold_2 = {key for key, value in essay_id_fold_dict.items() if value == 2}\n",
    "#     assert set(train_test_split_dataset[\"valid\"][\"essay_id\"]) == essay_id_fold_2\n",
    "#     assert len(set(train_test_split_dataset[\"valid\"][\"essay_id\"])) == 5769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:44.862553Z",
     "iopub.status.busy": "2024-05-25T10:37:44.862136Z",
     "iopub.status.idle": "2024-05-25T10:37:44.868472Z",
     "shell.execute_reply": "2024-05-25T10:37:44.867912Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# https://qiita.com/kaggle_grandmaster-arai-san/items/d59b2fb7142ec7e270a5#optimizedrounder\n",
    "class OptimizedRounder:\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 3\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 4\n",
    "            elif pred >= coef[3] and pred < coef[4]:\n",
    "                X_p[i] = 5\n",
    "            else:\n",
    "                X_p[i] = 6\n",
    "\n",
    "        ll = cohen_kappa_score(y, X_p, weights=\"quadratic\")\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "        self.coef_ = sp.optimize.minimize(\n",
    "            loss_partial, initial_coef, method=\"nelder-mead\"\n",
    "        )\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 3\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 4\n",
    "            elif pred >= coef[3] and pred < coef[4]:\n",
    "                X_p[i] = 5\n",
    "            else:\n",
    "                X_p[i] = 6\n",
    "        return X_p\n",
    "\n",
    "    @property\n",
    "    def coefficients(self):\n",
    "        return self.coef_[\"x\"]\n",
    "\n",
    "\n",
    "# optR = OptimizedRounder()\n",
    "# optR.fit(valid_pred, valid_dataset[\"labels\"])\n",
    "# print(optR.coefficients)\n",
    "\n",
    "# optimized = optR.predict(valid_pred, optR.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:44.870372Z",
     "iopub.status.busy": "2024-05-25T10:37:44.870101Z",
     "iopub.status.idle": "2024-05-25T10:37:44.873795Z",
     "shell.execute_reply": "2024-05-25T10:37:44.873233Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/cdeotte/deberta-v3-small-starter-cv-0-820-lb-0-800\n",
    "# def compute_metrics_for_classification(eval_pred):\n",
    "\n",
    "#     predictions, labels = eval_pred\n",
    "#     qwk = cohen_kappa_score(labels, predictions.argmax(-1), weights=\"quadratic\")\n",
    "#     results = {\"qwk\": qwk}\n",
    "#     return results\n",
    "\n",
    "\n",
    "# def compute_metrics_for_regression(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     mse = mean_squared_error(labels, predictions)\n",
    "#     return {\"mse\": mse}\n",
    "\n",
    "\n",
    "def compute_metrics_for_regression_opt(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    optR = OptimizedRounder()\n",
    "    optR.fit(predictions, labels)\n",
    "    optimized = optR.predict(predictions, optR.coefficients)\n",
    "    print(optR.coefficients)\n",
    "\n",
    "    qwk = cohen_kappa_score(labels, optimized, weights=\"quadratic\")\n",
    "    return {\"qwk\": qwk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:44.875689Z",
     "iopub.status.busy": "2024-05-25T10:37:44.875267Z",
     "iopub.status.idle": "2024-05-25T10:37:44.883890Z",
     "shell.execute_reply": "2024-05-25T10:37:44.883336Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/seoyunje/aes-2-custom-deberta-with-different-header\n",
    "class MaxPooling(ContextPooler):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        max_embeddings, _ = last_hidden_state.max(1)\n",
    "        return max_embeddings\n",
    "\n",
    "\n",
    "class MeanPooling(ContextPooler):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = (\n",
    "            attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        )\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)  # ゼロ除算を防ぐ\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "\n",
    "class MeanMaxPooling(ContextPooler):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.mean_pooler = MeanPooling(config)\n",
    "        self.max_pooler = MaxPooling(config)\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        mean_pooling_embeddings = self.mean_pooler(last_hidden_state, attention_mask)\n",
    "        max_pooling_embeddings = self.max_pooler(last_hidden_state, attention_mask)\n",
    "\n",
    "        mean_max_embeddings = torch.cat(\n",
    "            (mean_pooling_embeddings, max_pooling_embeddings), 1\n",
    "        )\n",
    "\n",
    "        return mean_max_embeddings\n",
    "\n",
    "    @property\n",
    "    def output_dim(self):\n",
    "        return self.config.hidden_size * 2\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/competitions/feedback-prize-english-language-learning/discussion/361678\n",
    "class AttentionPooling(ContextPooler):\n",
    "    \"\"\"\n",
    "    mean poolingはそれぞれのtokenを等しく足し合わせる。\n",
    "    Attention Poolingは、それぞれのtokenに対する重みの層を新たに学習することで、\n",
    "    tokenに対する重み付けをより詳細に行うことができる。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        in_dim = config.hidden_size\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim),\n",
    "            nn.LayerNorm(in_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        w = self.attention(last_hidden_state).float()\n",
    "        w[attention_mask == 0] = float(\"-inf\")\n",
    "        w = torch.softmax(w, 1)\n",
    "        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n",
    "        return attention_embeddings\n",
    "\n",
    "\n",
    "# TODO: 1D-Conv,LSTM\n",
    "# https://www.ai-shift.co.jp/techblog/2145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:44.885741Z",
     "iopub.status.busy": "2024-05-25T10:37:44.885297Z",
     "iopub.status.idle": "2024-05-25T10:37:44.891246Z",
     "shell.execute_reply": "2024-05-25T10:37:44.890742Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://dev.classmethod.jp/articles/huggingface-usage-custom-model/\n",
    "# https://github.com/huggingface/transformers/blob/94b3f544a1f5e04b78d87a2ae32a7ac252e22e31/src/transformers/models/deberta_v2/modeling_deberta_v2.py#L1313\n",
    "class CustomDebertaSequenceClassification(DebertaV2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        num_labels = getattr(config, \"num_labels\", 2)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.deberta = DebertaV2Model(config)\n",
    "        # self.pooler = ContextPooler(config)\n",
    "        # self.pooler = MaxPooling(config)\n",
    "        self.pooler = MeanPooling(config)\n",
    "        # self.pooler = MeanMaxPooling(config)\n",
    "        # self.pooler = AttentionPooling(config)\n",
    "        output_dim = self.pooler.output_dim\n",
    "\n",
    "        self.classifier = nn.Linear(output_dim, num_labels)\n",
    "        drop_out = getattr(config, \"cls_dropout\", None)\n",
    "        drop_out = self.config.hidden_dropout_prob if drop_out is None else drop_out\n",
    "        self.dropout = StableDropout(drop_out)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.deberta.get_input_embeddings()\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.deberta.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        outputs = self.deberta(\n",
    "            input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        # CLSのみを利用する\n",
    "        # encoder_layer = outputs[0]\n",
    "        # pooled_output = self.pooler(encoder_layer) # torch.Size([8, 384])\n",
    "\n",
    "        pooled_output = self.pooler(outputs[\"last_hidden_state\"], attention_mask)\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = loss_fn(logits, labels.view(-1))\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:44.892675Z",
     "iopub.status.busy": "2024-05-25T10:37:44.892526Z",
     "iopub.status.idle": "2024-05-25T10:37:45.698501Z",
     "shell.execute_reply": "2024-05-25T10:37:45.697979Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # not use dropout\n",
    "# # https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/discussion/497832\n",
    "# config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "# config.attention_probs_dropout_prob = 0.0\n",
    "# config.hidden_dropout_prob = 0.0\n",
    "# config.num_labels = 1  # REGRESSION\n",
    "\n",
    "# # regression\n",
    "# # https://discuss.huggingface.co/t/how-to-set-up-trainer-for-a-regression/12994\n",
    "# # model = AutoModelForSequenceClassification.from_pretrained(\n",
    "# #     MODEL_NAME,\n",
    "# #     # num_labels=1,\n",
    "# #     config=config,\n",
    "# # )\n",
    "\n",
    "# # model = CustomModel.from_pretrained(MODEL_NAME, config=config)\n",
    "# # model = CustomDebertaSequenceClassification(config)\n",
    "# model = CustomDebertaSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
    "\n",
    "# # model.deberta.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)\n",
    "# model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)\n",
    "\n",
    "# # cast labels to float for regression\n",
    "# train_test_split_dataset = DatasetDict(\n",
    "#     {\n",
    "#         \"train\": train_test_split_dataset[\"train\"].cast_column(\n",
    "#             \"labels\", Value(dtype=\"float\")\n",
    "#         ),\n",
    "#         \"valid\": train_test_split_dataset[\"valid\"].cast_column(\n",
    "#             \"labels\", Value(dtype=\"float\")\n",
    "#         ),\n",
    "#     }\n",
    "# )\n",
    "# print(train_test_split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:45.700286Z",
     "iopub.status.busy": "2024-05-25T10:37:45.700115Z",
     "iopub.status.idle": "2024-05-25T10:37:45.702449Z",
     "shell.execute_reply": "2024-05-25T10:37:45.702001Z"
    }
   },
   "outputs": [],
   "source": [
    "# if not DEBUG:\n",
    "#     assert len(set(train_test_split_dataset[\"train\"][\"labels\"])) == NUM_LABELS\n",
    "#     assert len(set(train_test_split_dataset[\"valid\"][\"labels\"])) == NUM_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:45.704313Z",
     "iopub.status.busy": "2024-05-25T10:37:45.704156Z",
     "iopub.status.idle": "2024-05-25T10:37:45.706510Z",
     "shell.execute_reply": "2024-05-25T10:37:45.706079Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# from transformers import Trainer\n",
    "\n",
    "\n",
    "# class CustomTrainer(Trainer):\n",
    "#     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "#         labels = inputs.pop(\"labels\").float()  # ラベルを float 型に変換\n",
    "#         outputs = model(**inputs)\n",
    "#         logits = outputs[0]\n",
    "\n",
    "#         # MSE損失を計算\n",
    "#         loss_fct = nn.MSELoss()\n",
    "#         loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "\n",
    "#         return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:45.708600Z",
     "iopub.status.busy": "2024-05-25T10:37:45.708131Z",
     "iopub.status.idle": "2024-05-25T10:37:45.730862Z",
     "shell.execute_reply": "2024-05-25T10:37:45.730399Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_PATH,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=TRAIN_BS,\n",
    "    gradient_accumulation_steps=GRAD_ACC_NUM,\n",
    "    eval_accumulation_steps=GRAD_ACC_NUM,\n",
    "    per_device_eval_batch_size=EVAL_BS,\n",
    "    num_train_epochs=EPOCH,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=EVAL_STEP,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=SAVE_STEP,\n",
    "    save_total_limit=1,\n",
    "    seed=SEED,\n",
    "    metric_for_best_model=\"qwk\",\n",
    "    # metric_for_best_model=\"mse\",\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=LR_SCHE_TYPE,\n",
    "    report_to=REPORT_TO,\n",
    "    run_name=EXP_NAME,\n",
    "    load_best_model_at_end=True,\n",
    "    # fp16=True,\n",
    "    # fp16_full_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_test_split_dataset[\"train\"],\n",
    "#     eval_dataset=train_test_split_dataset[\"valid\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     # compute_metrics=compute_metrics_for_regression,\n",
    "#     compute_metrics=compute_metrics_for_regression_opt,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T10:37:45.733125Z",
     "iopub.status.busy": "2024-05-25T10:37:45.732954Z",
     "iopub.status.idle": "2024-05-25T11:20:29.913431Z",
     "shell.execute_reply": "2024-05-25T11:20:29.912799Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if TRAINING:\n",
    "#     # モデルの学習\n",
    "#     trainer.train()\n",
    "#     # ログの保存に利用したストレージを削除\n",
    "#     os.system(f\"rm -rf {MODEL_OUTPUT_PATH}/checkpoint-*\")\n",
    "#     # モデルの保存\n",
    "#     trainer.save_model(MODEL_OUTPUT_PATH)\n",
    "# else:\n",
    "#     # TRAINED_MODEL_PATHを用いて、学習済のモデルを読み込む\n",
    "#     model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#         TRAINED_MODEL_PATH,\n",
    "#         num_labels=1,\n",
    "#         problem_type=\"regression\",\n",
    "#     )\n",
    "\n",
    "#     args = TrainingArguments(\n",
    "#         \".\",\n",
    "#         per_device_eval_batch_size=4,\n",
    "#         report_to=\"none\",\n",
    "#         fp16=True,\n",
    "#     )\n",
    "\n",
    "#     trainer = Trainer(\n",
    "#         model=model,\n",
    "#         args=args,\n",
    "#         data_collator=data_collator,\n",
    "#         tokenizer=tokenizer,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_by_fold(train_dataset, fold: int):\n",
    "    train_dataset = train_dataset.map(\n",
    "        lambda x: {\"fold\": essay_id_fold_dict[x[\"essay_id\"]]}, num_proc=NUM_PROC\n",
    "    )\n",
    "\n",
    "    return DatasetDict(\n",
    "        {\n",
    "            \"train\": train_dataset.filter(\n",
    "                lambda x: x[\"fold\"] != fold, num_proc=NUM_PROC\n",
    "            ),\n",
    "            \"valid\": train_dataset.filter(\n",
    "                lambda x: x[\"fold\"] == fold, num_proc=NUM_PROC\n",
    "            ),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=8):  13%|█▎        | 13/100 [00:00<00:00, 105.88 examples/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'2CE045D2EBA4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/shinichiro.saito/automated_essay_scoring/.venv/lib/python3.11/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/shinichiro.saito/automated_essay_scoring/.venv/lib/python3.11/site-packages/datasets/utils/py_utils.py\", line 675, in _write_generator_to_queue\n    for i, result in enumerate(func(**kwargs)):\n  File \"/Users/shinichiro.saito/automated_essay_scoring/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 3517, in _map_single\n    example = apply_function_on_filtered_inputs(example, i, offset=offset)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/shinichiro.saito/automated_essay_scoring/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 3416, in apply_function_on_filtered_inputs\n    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/5f/gn0nt4qs4fs8b9bqs649m2b80000gn/T/ipykernel_7517/4294906149.py\", line 3, in <lambda>\n    lambda x: {\"fold\": essay_id_fold_dict[x[\"essay_id\"]]}, num_proc=NUM_PROC\n                       ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\nKeyError: '2CE045D2EBA4'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_FOLD):\n\u001b[0;32m----> 2\u001b[0m     train_test_split_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_train_test_by_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# to regression\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL_NAME)\n",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m, in \u001b[0;36mget_train_test_by_fold\u001b[0;34m(train_dataset, fold)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_train_test_by_fold\u001b[39m(train_dataset, fold: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43messay_id_fold_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43messay_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_PROC\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m      7\u001b[0m         {\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_dataset\u001b[38;5;241m.\u001b[39mfilter(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         }\n\u001b[1;32m     15\u001b[0m     )\n",
      "File \u001b[0;32m~/automated_essay_scoring/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/automated_essay_scoring/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/automated_essay_scoring/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:3248\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3242\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3243\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3244\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3245\u001b[0m     total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3246\u001b[0m     desc\u001b[38;5;241m=\u001b[39m(desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (num_proc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miflatmap_unordered\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs_per_job\u001b[49m\n\u001b[1;32m   3250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3252\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m~/automated_essay_scoring/.venv/lib/python3.11/site-packages/datasets/utils/py_utils.py:715\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m         \u001b[43m[\u001b[49m\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43masync_result\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43masync_results\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/automated_essay_scoring/.venv/lib/python3.11/site-packages/datasets/utils/py_utils.py:715\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m         [\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m~/automated_essay_scoring/.venv/lib/python3.11/site-packages/multiprocess/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mKeyError\u001b[0m: '2CE045D2EBA4'"
     ]
    }
   ],
   "source": [
    "for fold in range(NUM_FOLD):\n",
    "    train_test_split_dataset = get_train_test_by_fold(train_dataset, fold)\n",
    "\n",
    "    # to regression\n",
    "    config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "    config.attention_probs_dropout_prob = 0.0\n",
    "    config.hidden_dropout_prob = 0.0\n",
    "    config.num_labels = 1  # REGRESSION\n",
    "\n",
    "    model = CustomDebertaSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, config=config\n",
    "    )\n",
    "    model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)\n",
    "\n",
    "    # cast labels to float for regression\n",
    "    train_test_split_dataset = DatasetDict(\n",
    "        {\n",
    "            \"train\": train_test_split_dataset[\"train\"].cast_column(\n",
    "                \"labels\", Value(dtype=\"float\")\n",
    "            ),\n",
    "            \"valid\": train_test_split_dataset[\"valid\"].cast_column(\n",
    "                \"labels\", Value(dtype=\"float\")\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "    print(train_test_split_dataset)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_test_split_dataset[\"train\"],\n",
    "        eval_dataset=train_test_split_dataset[\"valid\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        # compute_metrics=compute_metrics_for_regression,\n",
    "        compute_metrics=compute_metrics_for_regression_opt,\n",
    "    )\n",
    "    if TRAINING:\n",
    "        # モデルの学習\n",
    "        trainer.train()\n",
    "        # ログの保存に利用したストレージを削除\n",
    "        os.system(f\"rm -rf {MODEL_OUTPUT_PATH}/checkpoint-*\")\n",
    "        # モデルの保存\n",
    "        trainer.save_model(MODEL_OUTPUT_PATH)\n",
    "    else:\n",
    "        # TRAINED_MODEL_PATHを用いて、学習済のモデルを読み込む\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            TRAINED_MODEL_PATH,\n",
    "            num_labels=1,\n",
    "            problem_type=\"regression\",\n",
    "        )\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            \".\",\n",
    "            per_device_eval_batch_size=4,\n",
    "            report_to=\"none\",\n",
    "            fp16=True,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "\n",
    "    # TODO: validのデータの保存、OOFの作成\n",
    "    # INFERRENCEのMAX_TOKENに揃えるために、validを作り直す\n",
    "    valid_dataset = train_test_split_dataset[\"valid\"].map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        fn_kwargs={\"max_token_length\": INFERENCE_MAX_LENGTH},\n",
    "        num_proc=NUM_PROC,\n",
    "    )\n",
    "\n",
    "    def add_valid_pred(example, idx, valid_pred):\n",
    "        example[\"valid_pred\"] = valid_pred[idx]\n",
    "        return example\n",
    "\n",
    "    valid_pred = trainer.predict(valid_dataset).predictions.flatten()\n",
    "    np.save(f\"{MODEL_OUTPUT_PATH}/valid_prediction_fold{fold}.npy\", valid_pred)\n",
    "\n",
    "    valid_dataset = valid_dataset.map(\n",
    "        add_valid_pred, with_indices=True, fn_kwargs={\"valid_pred\": valid_pred}\n",
    "    )\n",
    "\n",
    "    valid_dataset.save_to_disk(f\"{MODEL_OUTPUT_PATH}/valid_dataset_fold{fold}\")\n",
    "\n",
    "    # # for regression\n",
    "    # def clip_valid_pred(example):\n",
    "    #     # 四捨五入を実施\n",
    "    #     example[\"valid_pred\"] = np.clip(example[\"valid_pred\"], 1, 6).round()\n",
    "    #     return example\n",
    "\n",
    "    # valid_dataset = valid_dataset.map(clip_valid_pred)\n",
    "\n",
    "    # cv_score = cohen_kappa_score(\n",
    "    #     valid_dataset[\"labels\"], valid_dataset[\"valid_pred\"], weights=\"quadratic\"\n",
    "    # )\n",
    "\n",
    "    # print(f\"CV Score by round fold{fold}: {cv_score}\")\n",
    "\n",
    "    # optR = OptimizedRounder()\n",
    "    # optR.fit(valid_pred, valid_dataset[\"labels\"])\n",
    "    # print(optR.coefficients)\n",
    "\n",
    "    # optimized = optR.predict(valid_pred, optR.coefficients)\n",
    "\n",
    "    # np.save(f\"{MODEL_OUTPUT_PATH}/opt_thr_fold{fold}.npy\", optR.coefficients)\n",
    "\n",
    "    # cv_score = cohen_kappa_score(valid_dataset[\"labels\"], optimized, weights=\"quadratic\")\n",
    "    # print(f\"CV Score by NelderMead fold{fold}: {cv_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid_datasetの作成・保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:20:29.916083Z",
     "iopub.status.busy": "2024-05-25T11:20:29.915902Z",
     "iopub.status.idle": "2024-05-25T11:23:06.907163Z",
     "shell.execute_reply": "2024-05-25T11:23:06.906603Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # valid_dataset = train_test_split_dataset[\"valid\"]\n",
    "# # TRAININGをINFERRENCEでMAX_TOKENを変えるために、validを作り直す\n",
    "# valid_dataset = train_dataset.filter(\n",
    "#     lambda example: example[\"essay_id\"]\n",
    "#     in train_test_split_dataset[\"valid\"][\"essay_id\"],\n",
    "#     num_proc=NUM_PROC,\n",
    "# )\n",
    "\n",
    "# # labelsはfloatにする\n",
    "# valid_dataset = valid_dataset.cast_column(\"labels\", Value(dtype=\"float\"))\n",
    "\n",
    "# valid_dataset = valid_dataset.map(\n",
    "#     preprocess_function,\n",
    "#     batched=True,\n",
    "#     fn_kwargs={\"max_token_length\": INFERENCE_MAX_LENGTH},\n",
    "#     num_proc=NUM_PROC,\n",
    "# )\n",
    "\n",
    "\n",
    "# def add_valid_pred(example, idx, valid_pred):\n",
    "#     example[\"valid_pred\"] = valid_pred[idx]\n",
    "#     return example\n",
    "\n",
    "\n",
    "# valid_pred = trainer.predict(valid_dataset).predictions.flatten()\n",
    "\n",
    "# np.save(f\"{MODEL_OUTPUT_PATH}/valid_prediction.npy\", valid_pred)\n",
    "\n",
    "# valid_dataset = valid_dataset.map(\n",
    "#     add_valid_pred, with_indices=True, fn_kwargs={\"valid_pred\": valid_pred}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:06.910188Z",
     "iopub.status.busy": "2024-05-25T11:23:06.909500Z",
     "iopub.status.idle": "2024-05-25T11:23:06.982119Z",
     "shell.execute_reply": "2024-05-25T11:23:06.981493Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# valid_dataset.save_to_disk(f\"{MODEL_OUTPUT_PATH}/valid_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:06.984425Z",
     "iopub.status.busy": "2024-05-25T11:23:06.984241Z",
     "iopub.status.idle": "2024-05-25T11:23:07.680570Z",
     "shell.execute_reply": "2024-05-25T11:23:07.680184Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for regression\n",
    "def clip_valid_pred(example):\n",
    "    # 四捨五入を実施\n",
    "    example[\"valid_pred\"] = np.clip(example[\"valid_pred\"], 1, 6).round()\n",
    "    return example\n",
    "\n",
    "\n",
    "valid_dataset = valid_dataset.map(clip_valid_pred)\n",
    "\n",
    "cv_score = cohen_kappa_score(\n",
    "    valid_dataset[\"labels\"], valid_dataset[\"valid_pred\"], weights=\"quadratic\"\n",
    ")\n",
    "\n",
    "print(f\"CV Score by round: {cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:07.683243Z",
     "iopub.status.busy": "2024-05-25T11:23:07.682717Z",
     "iopub.status.idle": "2024-05-25T11:23:08.802266Z",
     "shell.execute_reply": "2024-05-25T11:23:08.801872Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optR = OptimizedRounder()\n",
    "optR.fit(valid_pred, valid_dataset[\"labels\"])\n",
    "print(optR.coefficients)\n",
    "\n",
    "optimized = optR.predict(valid_pred, optR.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:08.805034Z",
     "iopub.status.busy": "2024-05-25T11:23:08.804155Z",
     "iopub.status.idle": "2024-05-25T11:23:08.809822Z",
     "shell.execute_reply": "2024-05-25T11:23:08.809450Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(f\"{MODEL_OUTPUT_PATH}/opt_thr.npy\", optR.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:08.811899Z",
     "iopub.status.busy": "2024-05-25T11:23:08.811483Z",
     "iopub.status.idle": "2024-05-25T11:23:08.820301Z",
     "shell.execute_reply": "2024-05-25T11:23:08.819939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_score = cohen_kappa_score(valid_dataset[\"labels\"], optimized, weights=\"quadratic\")\n",
    "\n",
    "print(f\"CV Score by NelderMead: {cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:08.822342Z",
     "iopub.status.busy": "2024-05-25T11:23:08.821993Z",
     "iopub.status.idle": "2024-05-25T11:23:08.827893Z",
     "shell.execute_reply": "2024-05-25T11:23:08.827537Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output_textを保存\n",
    "with open(f\"{MODEL_OUTPUT_PATH}/cv_score.txt\", \"w\") as f:\n",
    "    f.write(str(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:08.829798Z",
     "iopub.status.busy": "2024-05-25T11:23:08.829517Z",
     "iopub.status.idle": "2024-05-25T11:23:09.246976Z",
     "shell.execute_reply": "2024-05-25T11:23:09.246559Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    valid_dataset[\"labels\"],\n",
    "    valid_dataset[\"valid_pred\"],\n",
    "    labels=[x for x in range(1, 7)],\n",
    ")\n",
    "\n",
    "draw_cm = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm, display_labels=[x for x in range(1, 7)]\n",
    ")\n",
    "\n",
    "draw_cm.plot()\n",
    "plt.savefig(f\"{MODEL_OUTPUT_PATH}/confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWSへのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:09.249445Z",
     "iopub.status.busy": "2024-05-25T11:23:09.248604Z",
     "iopub.status.idle": "2024-05-25T11:23:29.516396Z",
     "shell.execute_reply": "2024-05-25T11:23:29.515482Z"
    }
   },
   "outputs": [],
   "source": [
    "# S3へのアップロード\n",
    "if not DEBUG and UPLOAD_DATA_TO_S3:\n",
    "    # uninstall\n",
    "    !sudo rm /usr/bin/aws\n",
    "    !sudo rm /usr/bin/aws_completer\n",
    "    !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "    # install\n",
    "    !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "    !unzip -o -qq awscliv2.zip\n",
    "    !sudo ./aws/install --update\n",
    "\n",
    "    # upload\n",
    "    output_name = MODEL_OUTPUT_PATH.split(\"/\")[-1]\n",
    "    os.system(\n",
    "        f\"aws s3 cp --recursive {MODEL_OUTPUT_PATH} s3://automated-essay-scoring/trained_model/{output_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:29.519578Z",
     "iopub.status.busy": "2024-05-25T11:23:29.518828Z",
     "iopub.status.idle": "2024-05-25T11:23:29.521814Z",
     "shell.execute_reply": "2024-05-25T11:23:29.521424Z"
    }
   },
   "outputs": [],
   "source": [
    "# ダウンロード（参考）\n",
    "# !sudo rm /usr/bin/aws\n",
    "# !sudo rm /usr/bin/aws_completer\n",
    "# !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "# !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "# !unzip -o -qq awscliv2.zip\n",
    "# !sudo ./aws/install --update\n",
    "\n",
    "# !aws s3 cp --recursive s3://automated-essay-scoring/trained_model/e005-regression /notebooks/automated_essay_scoring/trained_models/e005-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Datasetへのupload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:29.523595Z",
     "iopub.status.busy": "2024-05-25T11:23:29.523438Z",
     "iopub.status.idle": "2024-05-25T11:23:42.047730Z",
     "shell.execute_reply": "2024-05-25T11:23:42.047197Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not DEBUG and UPLOAD_DATA_TO_KAGGLE:\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "        # if \"_\" in dataset_name:\n",
    "        #     raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "        dataset_metadata = {}\n",
    "        dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "        dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "        dataset_metadata[\"title\"] = dataset_name\n",
    "        with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=4)\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "    print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{MODEL_OUTPUT_PATH}\")\n",
    "    dataset_create_new(dataset_name=DATASET_NAME, upload_dir=MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ローカルからのデータの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:42.049892Z",
     "iopub.status.busy": "2024-05-25T11:23:42.049523Z",
     "iopub.status.idle": "2024-05-25T11:23:42.128213Z",
     "shell.execute_reply": "2024-05-25T11:23:42.127586Z"
    }
   },
   "outputs": [],
   "source": [
    "if not DEBUG and (UPLOAD_DATA_TO_S3 or UPLOAD_DATA_TO_KAGGLE):\n",
    "    # ローカルからは削除\n",
    "    os.system(f\"rm -rf {MODEL_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:42.130807Z",
     "iopub.status.busy": "2024-05-25T11:23:42.130374Z",
     "iopub.status.idle": "2024-05-25T11:23:48.476715Z",
     "shell.execute_reply": "2024-05-25T11:23:48.476149Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:48.479185Z",
     "iopub.status.busy": "2024-05-25T11:23:48.478979Z",
     "iopub.status.idle": "2024-05-25T11:23:48.481992Z",
     "shell.execute_reply": "2024-05-25T11:23:48.481521Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"finish Notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c281ab182f54d33aa30fbc25221cb92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d0b6f43d0c0d46319e868efc865ece48",
       "max": 5769,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c4ae4bad256d41d4af19acbe62400666",
       "tabbable": null,
       "tooltip": null,
       "value": 5769
      }
     },
     "13b4b90a7f9c404aabe895b070523f2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_207fb14b61c4468aa194d86ed654055a",
        "IPY_MODEL_b2cbe435696949dd9d24c2f20f6ed210",
        "IPY_MODEL_346e2888a3404f2ab59d53c9dcd8095a"
       ],
       "layout": "IPY_MODEL_8bb4ad43a28746a2bf65450096ce7004",
       "tabbable": null,
       "tooltip": null
      }
     },
     "207fb14b61c4468aa194d86ed654055a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5e63256749f845ca820faf83c8d78bda",
       "placeholder": "​",
       "style": "IPY_MODEL_7bde0193cb4a44ed9b14bad58fa25d43",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "268488d83a2b425e97e31665b390171a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_985af99c52ce4b39a29b20e44d25bf07",
       "placeholder": "​",
       "style": "IPY_MODEL_c359d0a8086e4f67a104c59d2d5503a3",
       "tabbable": null,
       "tooltip": null,
       "value": "Saving the dataset (1/1 shards): 100%"
      }
     },
     "2a8252d81e9f463e85cb23b999804596": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ed25eba61da47ab8d0346258319f549": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "346e2888a3404f2ab59d53c9dcd8095a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_35d8cbacd0444c67a887f4ee7cf58057",
       "placeholder": "​",
       "style": "IPY_MODEL_7cdf1f11273042388994ae8158ef1606",
       "tabbable": null,
       "tooltip": null,
       "value": " 5769/5769 [00:00&lt;00:00, 11422.46 examples/s]"
      }
     },
     "35d8cbacd0444c67a887f4ee7cf58057": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a1f4439e14b4cc0a99f0e8aae0e05b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "480366c3f3e5459b8f02e0435940c19b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2ed25eba61da47ab8d0346258319f549",
       "placeholder": "​",
       "style": "IPY_MODEL_5eb58435f78840be956f51379daac422",
       "tabbable": null,
       "tooltip": null,
       "value": " 5769/5769 [00:00&lt;00:00, 9011.00 examples/s]"
      }
     },
     "4c87cc49bcf8474fbbd0d951745b6cfa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ec6fedbc3874839a4dbca7a7bdd3358": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8c95df47e022467887b3aab87daf3276",
        "IPY_MODEL_ed5951a9ed4e455da3f4492e871ff030",
        "IPY_MODEL_480366c3f3e5459b8f02e0435940c19b"
       ],
       "layout": "IPY_MODEL_a8cacf6128004575a813b3a2191d616e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5e63256749f845ca820faf83c8d78bda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5eb58435f78840be956f51379daac422": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7bde0193cb4a44ed9b14bad58fa25d43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7cdf1f11273042388994ae8158ef1606": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8b88c4a9d4144875a91603152471efa0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8bb4ad43a28746a2bf65450096ce7004": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c95df47e022467887b3aab87daf3276": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dd0ea9c08bca4cdfbbe79108b0e8ee50",
       "placeholder": "​",
       "style": "IPY_MODEL_3a1f4439e14b4cc0a99f0e8aae0e05b5",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "985af99c52ce4b39a29b20e44d25bf07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9eed22b8dc7c4a098d61fc13d963d81f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a513972da6c948fab9b6a3a4e47d1f63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8cacf6128004575a813b3a2191d616e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2cbe435696949dd9d24c2f20f6ed210": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a513972da6c948fab9b6a3a4e47d1f63",
       "max": 5769,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8b88c4a9d4144875a91603152471efa0",
       "tabbable": null,
       "tooltip": null,
       "value": 5769
      }
     },
     "be105335424e418382f67dfafcfcd219": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "befab6d37c394c97895a4df042e7c434": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4c87cc49bcf8474fbbd0d951745b6cfa",
       "placeholder": "​",
       "style": "IPY_MODEL_cbe2fb9cf7f7493b8265c1627598df13",
       "tabbable": null,
       "tooltip": null,
       "value": " 5769/5769 [00:00&lt;00:00, 97650.99 examples/s]"
      }
     },
     "c359d0a8086e4f67a104c59d2d5503a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c4ae4bad256d41d4af19acbe62400666": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c8787eb9875948f9a3bcac93655f1bf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_268488d83a2b425e97e31665b390171a",
        "IPY_MODEL_0c281ab182f54d33aa30fbc25221cb92",
        "IPY_MODEL_befab6d37c394c97895a4df042e7c434"
       ],
       "layout": "IPY_MODEL_be105335424e418382f67dfafcfcd219",
       "tabbable": null,
       "tooltip": null
      }
     },
     "cbe2fb9cf7f7493b8265c1627598df13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d0b6f43d0c0d46319e868efc865ece48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd0ea9c08bca4cdfbbe79108b0e8ee50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed5951a9ed4e455da3f4492e871ff030": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a8252d81e9f463e85cb23b999804596",
       "max": 5769,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9eed22b8dc7c4a098d61fc13d963d81f",
       "tabbable": null,
       "tooltip": null,
       "value": 5769
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
