{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  目的\n",
    "cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path setting\n",
    "EXP_NAME = \"e048-cross-validation\"\n",
    "MODEL_NAME = \"microsoft/deberta-v3-xsmall\"\n",
    "COMPETITION_NAME = \"automated_essay_scoring\"\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME.split('/')[-1]}\"\n",
    "MODEL_OUTPUT_PATH = f\"trained_models/{EXP_NAME}\"\n",
    "\n",
    "# experiment parameter\n",
    "DEBUG = True\n",
    "TRAINING = True\n",
    "UPLOAD_DATA_TO_S3 = False\n",
    "UPLOAD_DATA_TO_KAGGLE = False\n",
    "WANDB = False\n",
    "\n",
    "NUM_FOLD = 3\n",
    "\n",
    "# model parameter\n",
    "# TRAINING_MAX_LENGTH= 512\n",
    "TRAINING_MAX_LENGTH = 1024\n",
    "INFERENCE_MAX_LENGTH = 1536\n",
    "SEED = 42\n",
    "EPOCH = 4\n",
    "LR = 2e-05\n",
    "TRAIN_BS = 8\n",
    "GRAD_ACC_NUM = 16\n",
    "EVAL_BS = 8\n",
    "SAVE_STEP = 0.1\n",
    "EVAL_STEP = 0.1\n",
    "LR_SCHE_TYPE = \"linear\"\n",
    "\n",
    "# TRAINED_MODEL_PATH = (\n",
    "#     \"/notebooks/\" + \"automated_essay_scoring/trained_models/e016-not-use-dropout\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 17 23:05:08 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   28C    P8    22W / 300W |      1MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/automated_essay_scoring/automated_essay_scoring/exp\n",
      "Jupyter Lab!\n",
      "../../data\n",
      "/notebooks/automated_essay_scoring/automated_essay_scoring/exp\n",
      "Jupyter Lab!\n",
      "../../trained_models/e048-cross-validation\n"
     ]
    }
   ],
   "source": [
    "def resolve_path(base_path: str) -> str:\n",
    "    import os\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    if cwd == f\"/notebooks\":\n",
    "        print(\"Jupyter Kernel By VSCode!\")\n",
    "        return f\"/notebooks/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}\":\n",
    "        print(\"nohup!\")\n",
    "        return base_path\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}/{COMPETITION_NAME}/exp\":\n",
    "        print(\"Jupyter Lab!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    elif cwd.startswith(\"/Users/\"):\n",
    "        print(\"Local VSCode!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment\")\n",
    "\n",
    "\n",
    "DATA_PATH = resolve_path(DATA_PATH)\n",
    "print(DATA_PATH)\n",
    "MODEL_OUTPUT_PATH = resolve_path(MODEL_OUTPUT_PATH)\n",
    "print(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_dataset_name(dataset_name: str) -> None:\n",
    "    if len(dataset_name) < 6 or len(dataset_name) > 50:\n",
    "        raise Exception(\n",
    "            f\"データセットの文字列は6~50文字にしてください。現在{len(DATASET_NAME)}文字\"\n",
    "        )\n",
    "    if \"_\" in dataset_name:\n",
    "        raise Exception(\"datasetの名称に_の使用は禁止です\")\n",
    "\n",
    "\n",
    "validate_dataset_name(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq polars==0.20.23\n",
    "%pip install -qq transformers==4.40.1\n",
    "%pip install -qq datasets==2.19.0\n",
    "%pip install -qq evaluate==0.4.2\n",
    "%pip install -qq seqeval==1.2.2\n",
    "%pip install -qq accelerate==0.30.0\n",
    "%pip install -qq python-dotenv==1.0.1\n",
    "%pip install -qq wandb==0.16.6\n",
    "\n",
    "# formatter\n",
    "%pip install -qq black isort\n",
    "\n",
    "%pip install -qq kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 23:05:55.997766: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-17 23:05:55.997880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-17 23:05:56.083501: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-17 23:05:56.248626: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-17 23:05:57.636640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "import wandb\n",
    "from datasets import DatasetDict, Value, concatenate_datasets, load_dataset\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tokenizers import AddedToken\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    DebertaV2PreTrainedModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import (\n",
    "    ContextPooler,\n",
    "    StableDropout,\n",
    "    DebertaV2Model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "NUM_PROC = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "assert transformers.__version__ == \"4.40.1\"\n",
    "assert datasets.__version__ == \"2.19.0\"\n",
    "assert evaluate.__version__ == \"0.4.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed the same seed to all\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(f\"{DATA_PATH}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'none'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "    wandb.init(project=\"automated_essay_scoring\", name=EXP_NAME)\n",
    "    REPORT_TO = \"wandb\"\n",
    "else:\n",
    "    REPORT_TO = \"none\"\n",
    "\n",
    "REPORT_TO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['essay_id', 'full_text', 'score', 'flag'],\n",
       "    num_rows: 17307\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=f\"{DATA_PATH}/train.csv\",\n",
    "    split=\"train\",\n",
    ").map(lambda example: {\"flag\": \"original\"})\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['essay_id', 'full_text', 'score', 'flag'],\n",
       "    num_rows: 13125\n",
       "})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 追加データ\n",
    "persuade_dataset = (\n",
    "    load_dataset(\n",
    "        \"csv\",\n",
    "        data_files={\"train\": f\"{DATA_PATH}/persuade_w_is_tr_con_as_num.csv\"},\n",
    "        split=\"train\",\n",
    "    )\n",
    "    .filter(lambda x: not x[\"is_train_contains\"], num_proc=NUM_PROC)\n",
    "    .select_columns([\"essay_id_comp\", \"full_text\", \"holistic_essay_score\"])\n",
    "    .rename_columns({\"essay_id_comp\": \"essay_id\", \"holistic_essay_score\": \"score\"})\n",
    "    .map(lambda example: {\"flag\": \"persuade\"})\n",
    ")\n",
    "\n",
    "persuade_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ced8e7d61d48b6b2dfbc63235a6e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/13125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['essay_id', 'full_text', 'score', 'flag'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuade_dataset.filter(lambda x: x[\"essay_id\"] == '5.75E+11', num_proc=NUM_PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# データの結合\n",
    "train_dataset = concatenate_datasets([train_dataset, persuade_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train_dataset = train_dataset.shuffle(seed=SEED)\n",
    "    train_dataset = train_dataset.select(range(100))\n",
    "    EPOCH = 1\n",
    "    SAVE_STEP = 0.5\n",
    "    EVAL_STEP = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf83497fb787480a83335d28303555bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5814022d7f34f8d81d127f9f18ee68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35aa536c1a1447792f96d157d3bf12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.add_tokens(AddedToken(\"\\n\", normalized=False))\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c7c1d31b934bb788dfe01eb4ebf63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples, max_token_length: int):\n",
    "    return tokenizer(\n",
    "        examples[\"full_text\"],\n",
    "        max_length=max_token_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    fn_kwargs={\"max_token_length\": TRAINING_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column(\"score\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_dataset[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(f\"{DATA_PATH}/essay_id_fold_dict.json\") as f:\n",
    "with open(f\"{DATA_PATH}/essay_id_fold_by_slp_dict.json\") as f: # score, text_len, promptでのstrarify\n",
    "    essay_id_fold_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['essay_id', 'full_text', 'labels', 'flag', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 外部データなし\n",
    "# def get_train_test_split_dataset(train_dataset):\n",
    "#     train_dataset = train_dataset.map(\n",
    "#         lambda x: {\"fold\": essay_id_fold_dict[x[\"essay_id\"]]}, num_proc=NUM_PROC\n",
    "#     )\n",
    "\n",
    "#     return DatasetDict(\n",
    "#         {\n",
    "#             \"train\": train_dataset.filter(lambda x: x[\"fold\"] != 2, num_proc=NUM_PROC),\n",
    "#             \"valid\": train_dataset.filter(lambda x: x[\"fold\"] == 2, num_proc=NUM_PROC),\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "\n",
    "# train_test_split_dataset = get_train_test_split_dataset(train_dataset)\n",
    "\n",
    "\n",
    "# # 外部データあり\n",
    "# # def get_train_test_split_dataset_w_external(train_dataset):\n",
    "# #     original_dataset = train_dataset.filter(\n",
    "# #         lambda x: x[\"flag\"] == \"original\", num_proc=NUM_PROC\n",
    "# #     )\n",
    "\n",
    "# #     external_train_dataset = train_dataset.filter(\n",
    "# #         lambda x: x[\"flag\"] != \"original\", num_proc=NUM_PROC\n",
    "# #     )\n",
    "\n",
    "# #     original_dataset = original_dataset.map(\n",
    "# #         lambda x: {\"fold\": essay_id_fold_dict[x[\"essay_id\"]]}, num_proc=NUM_PROC\n",
    "# #     )\n",
    "\n",
    "# #     original_train_dataset = original_dataset.filter(\n",
    "# #         lambda x: x[\"fold\"] != 2, num_proc=NUM_PROC\n",
    "# #     )\n",
    "# #     original_valid_dataset = original_dataset.filter(\n",
    "# #         lambda x: x[\"fold\"] == 2, num_proc=NUM_PROC\n",
    "# #     )\n",
    "\n",
    "# #     train_test_split_dataset = DatasetDict(\n",
    "# #         {\n",
    "# #             \"train\": concatenate_datasets(\n",
    "# #                 [original_train_dataset, external_train_dataset]\n",
    "# #             ),\n",
    "# #             \"valid\": original_valid_dataset,\n",
    "# #         }\n",
    "# #     )\n",
    "\n",
    "# #     return train_test_split_dataset\n",
    "\n",
    "\n",
    "# # train_test_split_dataset = get_train_test_split_dataset_w_external(train_dataset)\n",
    "\n",
    "# # Check\n",
    "# # assert set(train_test_split_dataset[\"train\"][\"fold\"]) == {0, 1}\n",
    "# assert set(train_test_split_dataset[\"valid\"][\"fold\"]) == {2}\n",
    "\n",
    "# if not DEBUG:\n",
    "#     essay_id_fold_2 = {key for key, value in essay_id_fold_dict.items() if value == 2}\n",
    "#     assert set(train_test_split_dataset[\"valid\"][\"essay_id\"]) == essay_id_fold_2\n",
    "#     assert len(set(train_test_split_dataset[\"valid\"][\"essay_id\"])) == 5769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# https://qiita.com/kaggle_grandmaster-arai-san/items/d59b2fb7142ec7e270a5#optimizedrounder\n",
    "class OptimizedRounder:\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 3\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 4\n",
    "            elif pred >= coef[3] and pred < coef[4]:\n",
    "                X_p[i] = 5\n",
    "            else:\n",
    "                X_p[i] = 6\n",
    "\n",
    "        ll = cohen_kappa_score(y, X_p, weights=\"quadratic\")\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "        self.coef_ = sp.optimize.minimize(\n",
    "            loss_partial, initial_coef, method=\"nelder-mead\"\n",
    "        )\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 3\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 4\n",
    "            elif pred >= coef[3] and pred < coef[4]:\n",
    "                X_p[i] = 5\n",
    "            else:\n",
    "                X_p[i] = 6\n",
    "        return X_p\n",
    "\n",
    "    @property\n",
    "    def coefficients(self):\n",
    "        return self.coef_[\"x\"]\n",
    "\n",
    "\n",
    "# optR = OptimizedRounder()\n",
    "# optR.fit(valid_pred, valid_dataset[\"labels\"])\n",
    "# print(optR.coefficients)\n",
    "\n",
    "# optimized = optR.predict(valid_pred, optR.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/cdeotte/deberta-v3-small-starter-cv-0-820-lb-0-800\n",
    "# def compute_metrics_for_classification(eval_pred):\n",
    "\n",
    "#     predictions, labels = eval_pred\n",
    "#     qwk = cohen_kappa_score(labels, predictions.argmax(-1), weights=\"quadratic\")\n",
    "#     results = {\"qwk\": qwk}\n",
    "#     return results\n",
    "\n",
    "\n",
    "# def compute_metrics_for_regression(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     mse = mean_squared_error(labels, predictions)\n",
    "#     return {\"mse\": mse}\n",
    "\n",
    "\n",
    "def compute_metrics_for_regression_opt(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    optR = OptimizedRounder()\n",
    "    optR.fit(predictions, labels)\n",
    "    optimized = optR.predict(predictions, optR.coefficients)\n",
    "    print(optR.coefficients)\n",
    "\n",
    "    qwk = cohen_kappa_score(labels, optimized, weights=\"quadratic\")\n",
    "    return {\"qwk\": qwk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/seoyunje/aes-2-custom-deberta-with-different-header\n",
    "class MaxPooling(ContextPooler):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        max_embeddings, _ = last_hidden_state.max(1)\n",
    "        return max_embeddings\n",
    "\n",
    "\n",
    "class MeanPooling(ContextPooler):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = (\n",
    "            attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        )\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)  # ゼロ除算を防ぐ\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "\n",
    "class MeanMaxPooling(ContextPooler):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.mean_pooler = MeanPooling(config)\n",
    "        self.max_pooler = MaxPooling(config)\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        mean_pooling_embeddings = self.mean_pooler(last_hidden_state, attention_mask)\n",
    "        max_pooling_embeddings = self.max_pooler(last_hidden_state, attention_mask)\n",
    "\n",
    "        mean_max_embeddings = torch.cat(\n",
    "            (mean_pooling_embeddings, max_pooling_embeddings), 1\n",
    "        )\n",
    "\n",
    "        return mean_max_embeddings\n",
    "\n",
    "    @property\n",
    "    def output_dim(self):\n",
    "        return self.config.hidden_size * 2\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/competitions/feedback-prize-english-language-learning/discussion/361678\n",
    "class AttentionPooling(ContextPooler):\n",
    "    \"\"\"\n",
    "    mean poolingはそれぞれのtokenを等しく足し合わせる。\n",
    "    Attention Poolingは、それぞれのtokenに対する重みの層を新たに学習することで、\n",
    "    tokenに対する重み付けをより詳細に行うことができる。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        in_dim = config.hidden_size\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim),\n",
    "            nn.LayerNorm(in_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        w = self.attention(last_hidden_state).float()\n",
    "        w[attention_mask == 0] = float(\"-inf\")\n",
    "        w = torch.softmax(w, 1)\n",
    "        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n",
    "        return attention_embeddings\n",
    "\n",
    "\n",
    "# TODO: 1D-Conv,LSTM\n",
    "# https://www.ai-shift.co.jp/techblog/2145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://dev.classmethod.jp/articles/huggingface-usage-custom-model/\n",
    "# https://github.com/huggingface/transformers/blob/94b3f544a1f5e04b78d87a2ae32a7ac252e22e31/src/transformers/models/deberta_v2/modeling_deberta_v2.py#L1313\n",
    "class CustomDebertaSequenceClassification(DebertaV2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        num_labels = getattr(config, \"num_labels\", 2)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.deberta = DebertaV2Model(config)\n",
    "        # self.pooler = ContextPooler(config)\n",
    "        # self.pooler = MaxPooling(config)\n",
    "        self.pooler = MeanPooling(config)\n",
    "        # self.pooler = MeanMaxPooling(config)\n",
    "        # self.pooler = AttentionPooling(config)\n",
    "        output_dim = self.pooler.output_dim\n",
    "\n",
    "        self.classifier = nn.Linear(output_dim, num_labels)\n",
    "        drop_out = getattr(config, \"cls_dropout\", None)\n",
    "        drop_out = self.config.hidden_dropout_prob if drop_out is None else drop_out\n",
    "        self.dropout = StableDropout(drop_out)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.deberta.get_input_embeddings()\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings):\n",
    "        self.deberta.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        outputs = self.deberta(\n",
    "            input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        # CLSのみを利用する\n",
    "        # encoder_layer = outputs[0]\n",
    "        # pooled_output = self.pooler(encoder_layer) # torch.Size([8, 384])\n",
    "\n",
    "        pooled_output = self.pooler(outputs[\"last_hidden_state\"], attention_mask)\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = loss_fn(logits, labels.view(-1))\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # not use dropout\n",
    "# # https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/discussion/497832\n",
    "# config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "# config.attention_probs_dropout_prob = 0.0\n",
    "# config.hidden_dropout_prob = 0.0\n",
    "# config.num_labels = 1  # REGRESSION\n",
    "\n",
    "# # regression\n",
    "# # https://discuss.huggingface.co/t/how-to-set-up-trainer-for-a-regression/12994\n",
    "# # model = AutoModelForSequenceClassification.from_pretrained(\n",
    "# #     MODEL_NAME,\n",
    "# #     # num_labels=1,\n",
    "# #     config=config,\n",
    "# # )\n",
    "\n",
    "# # model = CustomModel.from_pretrained(MODEL_NAME, config=config)\n",
    "# # model = CustomDebertaSequenceClassification(config)\n",
    "# model = CustomDebertaSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
    "\n",
    "# # model.deberta.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)\n",
    "# model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)\n",
    "\n",
    "# # cast labels to float for regression\n",
    "# train_test_split_dataset = DatasetDict(\n",
    "#     {\n",
    "#         \"train\": train_test_split_dataset[\"train\"].cast_column(\n",
    "#             \"labels\", Value(dtype=\"float\")\n",
    "#         ),\n",
    "#         \"valid\": train_test_split_dataset[\"valid\"].cast_column(\n",
    "#             \"labels\", Value(dtype=\"float\")\n",
    "#         ),\n",
    "#     }\n",
    "# )\n",
    "# print(train_test_split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if not DEBUG:\n",
    "#     assert len(set(train_test_split_dataset[\"train\"][\"labels\"])) == NUM_LABELS\n",
    "#     assert len(set(train_test_split_dataset[\"valid\"][\"labels\"])) == NUM_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# from transformers import Trainer\n",
    "\n",
    "\n",
    "# class CustomTrainer(Trainer):\n",
    "#     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "#         labels = inputs.pop(\"labels\").float()  # ラベルを float 型に変換\n",
    "#         outputs = model(**inputs)\n",
    "#         logits = outputs[0]\n",
    "\n",
    "#         # MSE損失を計算\n",
    "#         loss_fct = nn.MSELoss()\n",
    "#         loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "\n",
    "#         return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_PATH,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=TRAIN_BS,\n",
    "    gradient_accumulation_steps=GRAD_ACC_NUM,\n",
    "    eval_accumulation_steps=GRAD_ACC_NUM,\n",
    "    per_device_eval_batch_size=EVAL_BS,\n",
    "    num_train_epochs=EPOCH,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=EVAL_STEP,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=SAVE_STEP,\n",
    "    save_total_limit=1,\n",
    "    seed=SEED,\n",
    "    metric_for_best_model=\"qwk\",\n",
    "    # metric_for_best_model=\"mse\",\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=LR_SCHE_TYPE,\n",
    "    report_to=REPORT_TO,\n",
    "    run_name=EXP_NAME,\n",
    "    load_best_model_at_end=True,\n",
    "    # fp16=True,\n",
    "    # fp16_full_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_test_split_dataset[\"train\"],\n",
    "#     eval_dataset=train_test_split_dataset[\"valid\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     # compute_metrics=compute_metrics_for_regression,\n",
    "#     compute_metrics=compute_metrics_for_regression_opt,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if TRAINING:\n",
    "#     # モデルの学習\n",
    "#     trainer.train()\n",
    "#     # ログの保存に利用したストレージを削除\n",
    "#     os.system(f\"rm -rf {MODEL_OUTPUT_PATH}/checkpoint-*\")\n",
    "#     # モデルの保存\n",
    "#     trainer.save_model(MODEL_OUTPUT_PATH)\n",
    "# else:\n",
    "#     # TRAINED_MODEL_PATHを用いて、学習済のモデルを読み込む\n",
    "#     model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#         TRAINED_MODEL_PATH,\n",
    "#         num_labels=1,\n",
    "#         problem_type=\"regression\",\n",
    "#     )\n",
    "\n",
    "#     args = TrainingArguments(\n",
    "#         \".\",\n",
    "#         per_device_eval_batch_size=4,\n",
    "#         report_to=\"none\",\n",
    "#         fp16=True,\n",
    "#     )\n",
    "\n",
    "#     trainer = Trainer(\n",
    "#         model=model,\n",
    "#         args=args,\n",
    "#         data_collator=data_collator,\n",
    "#         tokenizer=tokenizer,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_test_by_fold(train_dataset, fold: int):\n",
    "    train_dataset = train_dataset.map(\n",
    "        lambda x: {\"fold\": essay_id_fold_dict[x[\"essay_id\"]]}, num_proc=NUM_PROC\n",
    "    )\n",
    "\n",
    "    return DatasetDict(\n",
    "        {\n",
    "            \"train\": train_dataset.filter(\n",
    "                lambda x: x[\"fold\"] != fold, num_proc=NUM_PROC\n",
    "            ),\n",
    "            \"valid\": train_dataset.filter(\n",
    "                lambda x: x[\"fold\"] == fold, num_proc=NUM_PROC\n",
    "            ),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of CustomDebertaSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['essay_id', 'full_text', 'labels', 'flag', 'input_ids', 'token_type_ids', 'attention_mask', 'fold'],\n",
      "        num_rows: 62\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['essay_id', 'full_text', 'labels', 'flag', 'input_ids', 'token_type_ids', 'attention_mask', 'fold'],\n",
      "        num_rows: 38\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Qwk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.292347</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 2.5 3.5 4.5 5.5]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 2.5 3.5 4.5 5.5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c431299de944e68a8e03e8bcac4883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of CustomDebertaSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['essay_id', 'full_text', 'labels', 'flag', 'input_ids', 'token_type_ids', 'attention_mask', 'fold'],\n",
      "        num_rows: 64\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['essay_id', 'full_text', 'labels', 'flag', 'input_ids', 'token_type_ids', 'attention_mask', 'fold'],\n",
      "        num_rows: 36\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Qwk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>12.651948</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 2.5 3.5 4.5 5.5]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 2.5 3.5 4.5 5.5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0af7daa17e4830a51cd199674629a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of CustomDebertaSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['essay_id', 'full_text', 'labels', 'flag', 'input_ids', 'token_type_ids', 'attention_mask', 'fold'],\n",
      "        num_rows: 74\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['essay_id', 'full_text', 'labels', 'flag', 'input_ids', 'token_type_ids', 'attention_mask', 'fold'],\n",
      "        num_rows: 26\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Qwk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.048211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 2.5 3.5 4.5 5.5]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 2.5 3.5 4.5 5.5]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a16c6ff17bd4e8abcc4c647c3eeca2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/26 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(NUM_FOLD):\n",
    "    train_test_split_dataset = get_train_test_by_fold(train_dataset, fold)\n",
    "\n",
    "    # to regression\n",
    "    config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "    config.attention_probs_dropout_prob = 0.0\n",
    "    config.hidden_dropout_prob = 0.0\n",
    "    config.num_labels = 1  # REGRESSION\n",
    "\n",
    "    model = CustomDebertaSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, config=config\n",
    "    )\n",
    "    model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)\n",
    "\n",
    "    # cast labels to float for regression\n",
    "    train_test_split_dataset = DatasetDict(\n",
    "        {\n",
    "            \"train\": train_test_split_dataset[\"train\"].cast_column(\n",
    "                \"labels\", Value(dtype=\"float\")\n",
    "            ),\n",
    "            \"valid\": train_test_split_dataset[\"valid\"].cast_column(\n",
    "                \"labels\", Value(dtype=\"float\")\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "    print(train_test_split_dataset)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_test_split_dataset[\"train\"],\n",
    "        eval_dataset=train_test_split_dataset[\"valid\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        # compute_metrics=compute_metrics_for_regression,\n",
    "        compute_metrics=compute_metrics_for_regression_opt,\n",
    "    )\n",
    "    if TRAINING:\n",
    "        # モデルの学習\n",
    "        trainer.train()\n",
    "        # ログの保存に利用したストレージを削除\n",
    "        os.system(f\"rm -rf {MODEL_OUTPUT_PATH}/checkpoint-*\")\n",
    "        # モデルの保存\n",
    "        trainer.save_model(f\"{MODEL_OUTPUT_PATH}/model_fold_{fold}\")\n",
    "    else:\n",
    "        # TRAINED_MODEL_PATHを用いて、学習済のモデルを読み込む\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            TRAINED_MODEL_PATH,\n",
    "            num_labels=1,\n",
    "            problem_type=\"regression\",\n",
    "        )\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            \".\",\n",
    "            per_device_eval_batch_size=4,\n",
    "            report_to=\"none\",\n",
    "            fp16=True,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "\n",
    "    # INFERRENCEのMAX_TOKENに揃えるために、validを作り直す\n",
    "    valid_dataset = train_test_split_dataset[\"valid\"].map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        fn_kwargs={\"max_token_length\": INFERENCE_MAX_LENGTH},\n",
    "        num_proc=NUM_PROC,\n",
    "    )\n",
    "\n",
    "    def add_valid_pred(example, idx, valid_pred):\n",
    "        example[\"valid_pred\"] = valid_pred[idx]\n",
    "        return example\n",
    "\n",
    "    valid_pred = trainer.predict(valid_dataset).predictions.flatten()\n",
    "    np.save(f\"{MODEL_OUTPUT_PATH}/valid_prediction_fold{fold}.npy\", valid_pred)\n",
    "\n",
    "    valid_dataset = valid_dataset.map(\n",
    "        add_valid_pred, with_indices=True, fn_kwargs={\"valid_pred\": valid_pred}\n",
    "    )\n",
    "\n",
    "    valid_dataset.save_to_disk(f\"{MODEL_OUTPUT_PATH}/valid_dataset_fold{fold}\")\n",
    "\n",
    "    # # for regression\n",
    "    # def clip_valid_pred(example):\n",
    "    #     # 四捨五入を実施\n",
    "    #     example[\"valid_pred\"] = np.clip(example[\"valid_pred\"], 1, 6).round()\n",
    "    #     return example\n",
    "\n",
    "    # valid_dataset = valid_dataset.map(clip_valid_pred)\n",
    "\n",
    "    # cv_score = cohen_kappa_score(\n",
    "    #     valid_dataset[\"labels\"], valid_dataset[\"valid_pred\"], weights=\"quadratic\"\n",
    "    # )\n",
    "\n",
    "    # print(f\"CV Score by round fold{fold}: {cv_score}\")\n",
    "\n",
    "    # optR = OptimizedRounder()\n",
    "    # optR.fit(valid_pred, valid_dataset[\"labels\"])\n",
    "    # print(optR.coefficients)\n",
    "\n",
    "    # optimized = optR.predict(valid_pred, optR.coefficients)\n",
    "\n",
    "    # np.save(f\"{MODEL_OUTPUT_PATH}/opt_thr_fold{fold}.npy\", optR.coefficients)\n",
    "\n",
    "    # cv_score = cohen_kappa_score(valid_dataset[\"labels\"], optimized, weights=\"quadratic\")\n",
    "    # print(f\"CV Score by NelderMead fold{fold}: {cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: OOFの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A21A69767BEE',\n",
       " '5B9A78A026ED',\n",
       " '3adb427',\n",
       " 'ce30566',\n",
       " 'efe5189',\n",
       " 'cff70d1',\n",
       " '73A7CE028611',\n",
       " '5016DBF9E5A8',\n",
       " '5.75E+11',\n",
       " '2720b3c']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset[\"essay_id\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1682768017053604,\n",
       " 0.20376481115818024,\n",
       " 0.19558745622634888,\n",
       " 0.17770807445049286,\n",
       " 0.136262446641922,\n",
       " 0.17582549154758453,\n",
       " 0.1930599808692932,\n",
       " 0.22352048754692078,\n",
       " 0.18970085680484772,\n",
       " 0.13269630074501038]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset[\"valid_pred\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid_datasetの作成・保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:20:29.916083Z",
     "iopub.status.busy": "2024-05-25T11:20:29.915902Z",
     "iopub.status.idle": "2024-05-25T11:23:06.907163Z",
     "shell.execute_reply": "2024-05-25T11:23:06.906603Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # valid_dataset = train_test_split_dataset[\"valid\"]\n",
    "# # TRAININGをINFERRENCEでMAX_TOKENを変えるために、validを作り直す\n",
    "# valid_dataset = train_dataset.filter(\n",
    "#     lambda example: example[\"essay_id\"]\n",
    "#     in train_test_split_dataset[\"valid\"][\"essay_id\"],\n",
    "#     num_proc=NUM_PROC,\n",
    "# )\n",
    "\n",
    "# # labelsはfloatにする\n",
    "# valid_dataset = valid_dataset.cast_column(\"labels\", Value(dtype=\"float\"))\n",
    "\n",
    "# valid_dataset = valid_dataset.map(\n",
    "#     preprocess_function,\n",
    "#     batched=True,\n",
    "#     fn_kwargs={\"max_token_length\": INFERENCE_MAX_LENGTH},\n",
    "#     num_proc=NUM_PROC,\n",
    "# )\n",
    "\n",
    "\n",
    "# def add_valid_pred(example, idx, valid_pred):\n",
    "#     example[\"valid_pred\"] = valid_pred[idx]\n",
    "#     return example\n",
    "\n",
    "\n",
    "# valid_pred = trainer.predict(valid_dataset).predictions.flatten()\n",
    "\n",
    "# np.save(f\"{MODEL_OUTPUT_PATH}/valid_prediction.npy\", valid_pred)\n",
    "\n",
    "# valid_dataset = valid_dataset.map(\n",
    "#     add_valid_pred, with_indices=True, fn_kwargs={\"valid_pred\": valid_pred}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:06.910188Z",
     "iopub.status.busy": "2024-05-25T11:23:06.909500Z",
     "iopub.status.idle": "2024-05-25T11:23:06.982119Z",
     "shell.execute_reply": "2024-05-25T11:23:06.981493Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# valid_dataset.save_to_disk(f\"{MODEL_OUTPUT_PATH}/valid_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:06.984425Z",
     "iopub.status.busy": "2024-05-25T11:23:06.984241Z",
     "iopub.status.idle": "2024-05-25T11:23:07.680570Z",
     "shell.execute_reply": "2024-05-25T11:23:07.680184Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for regression\n",
    "def clip_valid_pred(example):\n",
    "    # 四捨五入を実施\n",
    "    example[\"valid_pred\"] = np.clip(example[\"valid_pred\"], 1, 6).round()\n",
    "    return example\n",
    "\n",
    "\n",
    "valid_dataset = valid_dataset.map(clip_valid_pred)\n",
    "\n",
    "cv_score = cohen_kappa_score(\n",
    "    valid_dataset[\"labels\"], valid_dataset[\"valid_pred\"], weights=\"quadratic\"\n",
    ")\n",
    "\n",
    "print(f\"CV Score by round: {cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:07.683243Z",
     "iopub.status.busy": "2024-05-25T11:23:07.682717Z",
     "iopub.status.idle": "2024-05-25T11:23:08.802266Z",
     "shell.execute_reply": "2024-05-25T11:23:08.801872Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optR = OptimizedRounder()\n",
    "optR.fit(valid_pred, valid_dataset[\"labels\"])\n",
    "print(optR.coefficients)\n",
    "\n",
    "optimized = optR.predict(valid_pred, optR.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:08.805034Z",
     "iopub.status.busy": "2024-05-25T11:23:08.804155Z",
     "iopub.status.idle": "2024-05-25T11:23:08.809822Z",
     "shell.execute_reply": "2024-05-25T11:23:08.809450Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(f\"{MODEL_OUTPUT_PATH}/opt_thr.npy\", optR.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:08.811899Z",
     "iopub.status.busy": "2024-05-25T11:23:08.811483Z",
     "iopub.status.idle": "2024-05-25T11:23:08.820301Z",
     "shell.execute_reply": "2024-05-25T11:23:08.819939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_score = cohen_kappa_score(valid_dataset[\"labels\"], optimized, weights=\"quadratic\")\n",
    "\n",
    "print(f\"CV Score by NelderMead: {cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:08.822342Z",
     "iopub.status.busy": "2024-05-25T11:23:08.821993Z",
     "iopub.status.idle": "2024-05-25T11:23:08.827893Z",
     "shell.execute_reply": "2024-05-25T11:23:08.827537Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output_textを保存\n",
    "with open(f\"{MODEL_OUTPUT_PATH}/cv_score.txt\", \"w\") as f:\n",
    "    f.write(str(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:08.829798Z",
     "iopub.status.busy": "2024-05-25T11:23:08.829517Z",
     "iopub.status.idle": "2024-05-25T11:23:09.246976Z",
     "shell.execute_reply": "2024-05-25T11:23:09.246559Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    valid_dataset[\"labels\"],\n",
    "    valid_dataset[\"valid_pred\"],\n",
    "    labels=[x for x in range(1, 7)],\n",
    ")\n",
    "\n",
    "draw_cm = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm, display_labels=[x for x in range(1, 7)]\n",
    ")\n",
    "\n",
    "draw_cm.plot()\n",
    "plt.savefig(f\"{MODEL_OUTPUT_PATH}/confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWSへのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:09.249445Z",
     "iopub.status.busy": "2024-05-25T11:23:09.248604Z",
     "iopub.status.idle": "2024-05-25T11:23:29.516396Z",
     "shell.execute_reply": "2024-05-25T11:23:29.515482Z"
    }
   },
   "outputs": [],
   "source": [
    "# S3へのアップロード\n",
    "if not DEBUG and UPLOAD_DATA_TO_S3:\n",
    "    # uninstall\n",
    "    !sudo rm /usr/bin/aws\n",
    "    !sudo rm /usr/bin/aws_completer\n",
    "    !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "    # install\n",
    "    !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "    !unzip -o -qq awscliv2.zip\n",
    "    !sudo ./aws/install --update\n",
    "\n",
    "    # upload\n",
    "    output_name = MODEL_OUTPUT_PATH.split(\"/\")[-1]\n",
    "    os.system(\n",
    "        f\"aws s3 cp --recursive {MODEL_OUTPUT_PATH} s3://automated-essay-scoring/trained_model/{output_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:29.519578Z",
     "iopub.status.busy": "2024-05-25T11:23:29.518828Z",
     "iopub.status.idle": "2024-05-25T11:23:29.521814Z",
     "shell.execute_reply": "2024-05-25T11:23:29.521424Z"
    }
   },
   "outputs": [],
   "source": [
    "# ダウンロード（参考）\n",
    "# !sudo rm /usr/bin/aws\n",
    "# !sudo rm /usr/bin/aws_completer\n",
    "# !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "# !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "# !unzip -o -qq awscliv2.zip\n",
    "# !sudo ./aws/install --update\n",
    "\n",
    "# !aws s3 cp --recursive s3://automated-essay-scoring/trained_model/e005-regression /notebooks/automated_essay_scoring/trained_models/e005-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Datasetへのupload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:29.523595Z",
     "iopub.status.busy": "2024-05-25T11:23:29.523438Z",
     "iopub.status.idle": "2024-05-25T11:23:42.047730Z",
     "shell.execute_reply": "2024-05-25T11:23:42.047197Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not DEBUG and UPLOAD_DATA_TO_KAGGLE:\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "        # if \"_\" in dataset_name:\n",
    "        #     raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "        dataset_metadata = {}\n",
    "        dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "        dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "        dataset_metadata[\"title\"] = dataset_name\n",
    "        with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=4)\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "    print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{MODEL_OUTPUT_PATH}\")\n",
    "    dataset_create_new(dataset_name=DATASET_NAME, upload_dir=MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ローカルからのデータの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:42.049892Z",
     "iopub.status.busy": "2024-05-25T11:23:42.049523Z",
     "iopub.status.idle": "2024-05-25T11:23:42.128213Z",
     "shell.execute_reply": "2024-05-25T11:23:42.127586Z"
    }
   },
   "outputs": [],
   "source": [
    "if not DEBUG and (UPLOAD_DATA_TO_S3 or UPLOAD_DATA_TO_KAGGLE):\n",
    "    # ローカルからは削除\n",
    "    os.system(f\"rm -rf {MODEL_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:42.130807Z",
     "iopub.status.busy": "2024-05-25T11:23:42.130374Z",
     "iopub.status.idle": "2024-05-25T11:23:48.476715Z",
     "shell.execute_reply": "2024-05-25T11:23:48.476149Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-25T11:23:48.479185Z",
     "iopub.status.busy": "2024-05-25T11:23:48.478979Z",
     "iopub.status.idle": "2024-05-25T11:23:48.481992Z",
     "shell.execute_reply": "2024-05-25T11:23:48.481521Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"finish Notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c281ab182f54d33aa30fbc25221cb92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d0b6f43d0c0d46319e868efc865ece48",
       "max": 5769,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c4ae4bad256d41d4af19acbe62400666",
       "tabbable": null,
       "tooltip": null,
       "value": 5769
      }
     },
     "13b4b90a7f9c404aabe895b070523f2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_207fb14b61c4468aa194d86ed654055a",
        "IPY_MODEL_b2cbe435696949dd9d24c2f20f6ed210",
        "IPY_MODEL_346e2888a3404f2ab59d53c9dcd8095a"
       ],
       "layout": "IPY_MODEL_8bb4ad43a28746a2bf65450096ce7004",
       "tabbable": null,
       "tooltip": null
      }
     },
     "207fb14b61c4468aa194d86ed654055a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5e63256749f845ca820faf83c8d78bda",
       "placeholder": "​",
       "style": "IPY_MODEL_7bde0193cb4a44ed9b14bad58fa25d43",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "268488d83a2b425e97e31665b390171a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_985af99c52ce4b39a29b20e44d25bf07",
       "placeholder": "​",
       "style": "IPY_MODEL_c359d0a8086e4f67a104c59d2d5503a3",
       "tabbable": null,
       "tooltip": null,
       "value": "Saving the dataset (1/1 shards): 100%"
      }
     },
     "2a8252d81e9f463e85cb23b999804596": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ed25eba61da47ab8d0346258319f549": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "346e2888a3404f2ab59d53c9dcd8095a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_35d8cbacd0444c67a887f4ee7cf58057",
       "placeholder": "​",
       "style": "IPY_MODEL_7cdf1f11273042388994ae8158ef1606",
       "tabbable": null,
       "tooltip": null,
       "value": " 5769/5769 [00:00&lt;00:00, 11422.46 examples/s]"
      }
     },
     "35d8cbacd0444c67a887f4ee7cf58057": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3a1f4439e14b4cc0a99f0e8aae0e05b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "480366c3f3e5459b8f02e0435940c19b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2ed25eba61da47ab8d0346258319f549",
       "placeholder": "​",
       "style": "IPY_MODEL_5eb58435f78840be956f51379daac422",
       "tabbable": null,
       "tooltip": null,
       "value": " 5769/5769 [00:00&lt;00:00, 9011.00 examples/s]"
      }
     },
     "4c87cc49bcf8474fbbd0d951745b6cfa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ec6fedbc3874839a4dbca7a7bdd3358": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8c95df47e022467887b3aab87daf3276",
        "IPY_MODEL_ed5951a9ed4e455da3f4492e871ff030",
        "IPY_MODEL_480366c3f3e5459b8f02e0435940c19b"
       ],
       "layout": "IPY_MODEL_a8cacf6128004575a813b3a2191d616e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5e63256749f845ca820faf83c8d78bda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5eb58435f78840be956f51379daac422": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7bde0193cb4a44ed9b14bad58fa25d43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7cdf1f11273042388994ae8158ef1606": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8b88c4a9d4144875a91603152471efa0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8bb4ad43a28746a2bf65450096ce7004": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c95df47e022467887b3aab87daf3276": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dd0ea9c08bca4cdfbbe79108b0e8ee50",
       "placeholder": "​",
       "style": "IPY_MODEL_3a1f4439e14b4cc0a99f0e8aae0e05b5",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "985af99c52ce4b39a29b20e44d25bf07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9eed22b8dc7c4a098d61fc13d963d81f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a513972da6c948fab9b6a3a4e47d1f63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8cacf6128004575a813b3a2191d616e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b2cbe435696949dd9d24c2f20f6ed210": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a513972da6c948fab9b6a3a4e47d1f63",
       "max": 5769,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8b88c4a9d4144875a91603152471efa0",
       "tabbable": null,
       "tooltip": null,
       "value": 5769
      }
     },
     "be105335424e418382f67dfafcfcd219": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "befab6d37c394c97895a4df042e7c434": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4c87cc49bcf8474fbbd0d951745b6cfa",
       "placeholder": "​",
       "style": "IPY_MODEL_cbe2fb9cf7f7493b8265c1627598df13",
       "tabbable": null,
       "tooltip": null,
       "value": " 5769/5769 [00:00&lt;00:00, 97650.99 examples/s]"
      }
     },
     "c359d0a8086e4f67a104c59d2d5503a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c4ae4bad256d41d4af19acbe62400666": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c8787eb9875948f9a3bcac93655f1bf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_268488d83a2b425e97e31665b390171a",
        "IPY_MODEL_0c281ab182f54d33aa30fbc25221cb92",
        "IPY_MODEL_befab6d37c394c97895a4df042e7c434"
       ],
       "layout": "IPY_MODEL_be105335424e418382f67dfafcfcd219",
       "tabbable": null,
       "tooltip": null
      }
     },
     "cbe2fb9cf7f7493b8265c1627598df13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d0b6f43d0c0d46319e868efc865ece48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd0ea9c08bca4cdfbbe79108b0e8ee50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed5951a9ed4e455da3f4492e871ff030": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a8252d81e9f463e85cb23b999804596",
       "max": 5769,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9eed22b8dc7c4a098d61fc13d963d81f",
       "tabbable": null,
       "tooltip": null,
       "value": 5769
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
