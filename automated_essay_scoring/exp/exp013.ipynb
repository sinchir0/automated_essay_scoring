{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  目的\n",
    "qwkloss(pat2)を使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:11:49.536270Z",
     "iopub.status.busy": "2024-05-18T05:11:49.536000Z",
     "iopub.status.idle": "2024-05-18T05:11:49.547679Z",
     "shell.execute_reply": "2024-05-18T05:11:49.546697Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path setting\n",
    "EXP_NAME = \"e013-cls-with-qwkloss-pat2\"\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "COMPETITION_NAME = \"automated_essay_scoring\"\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME.split('/')[-1]}\"\n",
    "MODEL_OUTPUT_PATH = f\"trained_models/{EXP_NAME}\"\n",
    "\n",
    "# experiment parameter\n",
    "DEBUG = False\n",
    "TRAINING = True\n",
    "UPLOAD_DATA_TO_S3 = True\n",
    "UPLOAD_DATA_TO_KAGGLE = True\n",
    "WANDB = True\n",
    "\n",
    "# model parameter\n",
    "TRAINING_MAX_LENGTH = 512\n",
    "# TRAINING_MAX_LENGTH = 1024\n",
    "# TRAINING_MAX_LENGTH= 2048\n",
    "SEED = 42\n",
    "EPOCH = 3\n",
    "LR = 2e-05\n",
    "TRAIN_BS = 2 # 8\n",
    "GRAD_ACC_NUM = 4 # 16\n",
    "EVAL_BS = 2 # 8\n",
    "SAVE_STEP = 0.1\n",
    "EVAL_STEP = 0.1\n",
    "NUM_LABELS = 6\n",
    "\n",
    "TRAINED_MODEL_PATH = \"/notebooks/automated_essay_scoring/trained_models/e012-cls-with-qwkloss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:11:49.553079Z",
     "iopub.status.busy": "2024-05-18T05:11:49.552689Z",
     "iopub.status.idle": "2024-05-18T05:11:49.761135Z",
     "shell.execute_reply": "2024-05-18T05:11:49.760085Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:11:49.765821Z",
     "iopub.status.busy": "2024-05-18T05:11:49.765453Z",
     "iopub.status.idle": "2024-05-18T05:11:49.887227Z",
     "shell.execute_reply": "2024-05-18T05:11:49.885774Z"
    }
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:11:49.892383Z",
     "iopub.status.busy": "2024-05-18T05:11:49.891948Z",
     "iopub.status.idle": "2024-05-18T05:11:49.900958Z",
     "shell.execute_reply": "2024-05-18T05:11:49.899976Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resolve_path(base_path: str) -> str:\n",
    "    import os\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    if cwd == f\"/notebooks\":\n",
    "        print(\"Jupyter Kernel By VSCode!\")\n",
    "        return f\"/notebooks/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}\":\n",
    "        print(\"nohup!\")\n",
    "        return base_path\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}/{COMPETITION_NAME}/exp\":\n",
    "        print(\"Jupyter Lab!\")\n",
    "        return f\"../../{base_path}\"\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment\")\n",
    "\n",
    "\n",
    "DATA_PATH = resolve_path(DATA_PATH)\n",
    "print(DATA_PATH)\n",
    "MODEL_OUTPUT_PATH = resolve_path(MODEL_OUTPUT_PATH)\n",
    "print(MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:11:49.904584Z",
     "iopub.status.busy": "2024-05-18T05:11:49.904249Z",
     "iopub.status.idle": "2024-05-18T05:11:49.910055Z",
     "shell.execute_reply": "2024-05-18T05:11:49.909054Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate_dataset_name(dataset_name: str) -> None:\n",
    "    if len(dataset_name) < 6 or len(dataset_name) > 50:\n",
    "        raise Exception(\n",
    "            f\"データセットの文字列は6~50文字にしてください。現在{len(DATASET_NAME)}文字\"\n",
    "        )\n",
    "    if \"_\" in dataset_name:\n",
    "        raise Exception(\"datasetの名称に_の使用は禁止です\")\n",
    "\n",
    "\n",
    "validate_dataset_name(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:11:49.913689Z",
     "iopub.status.busy": "2024-05-18T05:11:49.913412Z",
     "iopub.status.idle": "2024-05-18T05:12:32.580585Z",
     "shell.execute_reply": "2024-05-18T05:12:32.579416Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -qq polars==0.20.23\n",
    "%pip install -qq transformers==4.40.1\n",
    "%pip install -qq datasets==2.19.0\n",
    "%pip install -qq evaluate==0.4.2\n",
    "%pip install -qq seqeval==1.2.2\n",
    "%pip install -qq accelerate==0.30.0\n",
    "%pip install -qq python-dotenv==1.0.1\n",
    "%pip install -qq wandb==0.16.6\n",
    "\n",
    "# formatter\n",
    "%pip install -qq black isort\n",
    "\n",
    "%pip install -qq kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:32.583893Z",
     "iopub.status.busy": "2024-05-18T05:12:32.583627Z",
     "iopub.status.idle": "2024-05-18T05:12:44.251199Z",
     "shell.execute_reply": "2024-05-18T05:12:44.250264Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from datasets import ClassLabel, DatasetDict, Value, concatenate_datasets, load_dataset\n",
    "from tokenizers import AddedToken\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from tokenizers import AddedToken\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:44.254823Z",
     "iopub.status.busy": "2024-05-18T05:12:44.254563Z",
     "iopub.status.idle": "2024-05-18T05:12:44.258035Z",
     "shell.execute_reply": "2024-05-18T05:12:44.257300Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "NUM_PROC = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:44.260739Z",
     "iopub.status.busy": "2024-05-18T05:12:44.260502Z",
     "iopub.status.idle": "2024-05-18T05:12:44.264141Z",
     "shell.execute_reply": "2024-05-18T05:12:44.263366Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "assert transformers.__version__ == \"4.40.1\"\n",
    "assert datasets.__version__ == \"2.19.0\"\n",
    "assert evaluate.__version__ == \"0.4.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:44.267050Z",
     "iopub.status.busy": "2024-05-18T05:12:44.266829Z",
     "iopub.status.idle": "2024-05-18T05:12:44.271001Z",
     "shell.execute_reply": "2024-05-18T05:12:44.270293Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seed the same seed to all\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:44.274423Z",
     "iopub.status.busy": "2024-05-18T05:12:44.274152Z",
     "iopub.status.idle": "2024-05-18T05:12:44.287172Z",
     "shell.execute_reply": "2024-05-18T05:12:44.286276Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(f\"{DATA_PATH}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:44.330750Z",
     "iopub.status.busy": "2024-05-18T05:12:44.330449Z",
     "iopub.status.idle": "2024-05-18T05:12:46.436339Z",
     "shell.execute_reply": "2024-05-18T05:12:46.435535Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wandb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not DEBUG and WANDB:\n",
    "    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "    wandb.init(project=\"automated_essay_scoring\", name=EXP_NAME)\n",
    "    REPORT_TO = \"wandb\"\n",
    "else:\n",
    "    REPORT_TO = \"none\"\n",
    "\n",
    "REPORT_TO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:46.439995Z",
     "iopub.status.busy": "2024-05-18T05:12:46.439208Z",
     "iopub.status.idle": "2024-05-18T05:12:46.623664Z",
     "shell.execute_reply": "2024-05-18T05:12:46.623324Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['essay_id', 'full_text', 'score'],\n",
       "    num_rows: 17307\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\"train\": f\"{DATA_PATH}/train.csv\"},\n",
    "    split=\"train\",\n",
    ")\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:46.626437Z",
     "iopub.status.busy": "2024-05-18T05:12:46.626188Z",
     "iopub.status.idle": "2024-05-18T05:12:46.630177Z",
     "shell.execute_reply": "2024-05-18T05:12:46.629494Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train_dataset = train_dataset.select(range(100))\n",
    "    EPOCH = 1\n",
    "    SAVE_STEP = 0.5\n",
    "    EVAL_STEP = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:46.632320Z",
     "iopub.status.busy": "2024-05-18T05:12:46.632242Z",
     "iopub.status.idle": "2024-05-18T05:12:47.718857Z",
     "shell.execute_reply": "2024-05-18T05:12:47.718202Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.add_tokens(AddedToken(\"\\n\", normalized=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:47.722123Z",
     "iopub.status.busy": "2024-05-18T05:12:47.721864Z",
     "iopub.status.idle": "2024-05-18T05:12:47.770260Z",
     "shell.execute_reply": "2024-05-18T05:12:47.769595Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"full_text\"],\n",
    "        max_length=TRAINING_MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True, num_proc=NUM_PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:47.773874Z",
     "iopub.status.busy": "2024-05-18T05:12:47.773579Z",
     "iopub.status.idle": "2024-05-18T05:12:47.812347Z",
     "shell.execute_reply": "2024-05-18T05:12:47.811268Z"
    }
   },
   "outputs": [],
   "source": [
    "# cls\n",
    "# train_dataset = train_dataset.rename_column(\"score\", \"labels\")\n",
    "\n",
    "# reg\n",
    "score2label = {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5}\n",
    "\n",
    "label2score = {v: k for k, v in score2label.items()}\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda examples: {\"labels\": score2label[examples[\"score\"]]},\n",
    "    num_proc=NUM_PROC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:47.816015Z",
     "iopub.status.busy": "2024-05-18T05:12:47.815617Z",
     "iopub.status.idle": "2024-05-18T05:12:47.831030Z",
     "shell.execute_reply": "2024-05-18T05:12:47.829889Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_dataset[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:47.834578Z",
     "iopub.status.busy": "2024-05-18T05:12:47.834282Z",
     "iopub.status.idle": "2024-05-18T05:12:47.843166Z",
     "shell.execute_reply": "2024-05-18T05:12:47.842416Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"{DATA_PATH}/essay_id_fold_dict.json\") as f:\n",
    "    essay_id_fold_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:47.845834Z",
     "iopub.status.busy": "2024-05-18T05:12:47.845591Z",
     "iopub.status.idle": "2024-05-18T05:12:47.851264Z",
     "shell.execute_reply": "2024-05-18T05:12:47.850387Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['essay_id', 'full_text', 'score', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 17307\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:47.853900Z",
     "iopub.status.busy": "2024-05-18T05:12:47.853593Z",
     "iopub.status.idle": "2024-05-18T05:12:48.116009Z",
     "shell.execute_reply": "2024-05-18T05:12:48.115084Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    lambda x: {\"fold\": essay_id_fold_dict[x[\"essay_id\"]]}, num_proc=NUM_PROC\n",
    ")\n",
    "\n",
    "train_test_split_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_dataset.filter(lambda x: x[\"fold\"] != 2, num_proc=NUM_PROC),\n",
    "        \"valid\": train_dataset.filter(lambda x: x[\"fold\"] == 2, num_proc=NUM_PROC),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Check\n",
    "assert set(train_test_split_dataset[\"train\"][\"fold\"]) == {0, 1}\n",
    "assert set(train_test_split_dataset[\"valid\"][\"fold\"]) == {2}\n",
    "\n",
    "if not DEBUG:\n",
    "    essay_id_fold_2 = {key for key, value in essay_id_fold_dict.items() if value == 2}\n",
    "    assert set(train_test_split_dataset[\"valid\"][\"essay_id\"]) == essay_id_fold_2\n",
    "    assert len(set(train_test_split_dataset[\"valid\"][\"essay_id\"])) == 5769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:48.119186Z",
     "iopub.status.busy": "2024-05-18T05:12:48.118958Z",
     "iopub.status.idle": "2024-05-18T05:12:48.122907Z",
     "shell.execute_reply": "2024-05-18T05:12:48.122158Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:48.125386Z",
     "iopub.status.busy": "2024-05-18T05:12:48.125107Z",
     "iopub.status.idle": "2024-05-18T05:12:48.129764Z",
     "shell.execute_reply": "2024-05-18T05:12:48.129030Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy as sp\n",
    "# from functools import partial\n",
    "\n",
    "\n",
    "# # https://qiita.com/kaggle_grandmaster-arai-san/items/d59b2fb7142ec7e270a5#optimizedrounder\n",
    "# class OptimizedRounder:\n",
    "#     def __init__(self):\n",
    "#         self.coef_ = 0\n",
    "\n",
    "#     def _kappa_loss(self, coef, X, y):\n",
    "#         X_p = np.copy(X)\n",
    "#         for i, pred in enumerate(X_p):\n",
    "#             if pred < coef[0]:\n",
    "#                 X_p[i] = 1\n",
    "#             elif pred >= coef[0] and pred < coef[1]:\n",
    "#                 X_p[i] = 2\n",
    "#             elif pred >= coef[1] and pred < coef[2]:\n",
    "#                 X_p[i] = 3\n",
    "#             elif pred >= coef[2] and pred < coef[3]:\n",
    "#                 X_p[i] = 4\n",
    "#             elif pred >= coef[3] and pred < coef[4]:\n",
    "#                 X_p[i] = 5\n",
    "#             else:\n",
    "#                 X_p[i] = 6\n",
    "\n",
    "#         ll = cohen_kappa_score(y, X_p, weights=\"quadratic\")\n",
    "#         return -ll\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "#         initial_coef = [1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "#         self.coef_ = sp.optimize.minimize(\n",
    "#             loss_partial, initial_coef, method=\"nelder-mead\"\n",
    "#         )\n",
    "\n",
    "#     def predict(self, X, coef):\n",
    "#         X_p = np.copy(X)\n",
    "#         for i, pred in enumerate(X_p):\n",
    "#             if pred < coef[0]:\n",
    "#                 X_p[i] = 1\n",
    "#             elif pred >= coef[0] and pred < coef[1]:\n",
    "#                 X_p[i] = 2\n",
    "#             elif pred >= coef[1] and pred < coef[2]:\n",
    "#                 X_p[i] = 3\n",
    "#             elif pred >= coef[2] and pred < coef[3]:\n",
    "#                 X_p[i] = 4\n",
    "#             elif pred >= coef[3] and pred < coef[4]:\n",
    "#                 X_p[i] = 5\n",
    "#             else:\n",
    "#                 X_p[i] = 6\n",
    "#         return X_p\n",
    "\n",
    "#     @property\n",
    "#     def coefficients(self):\n",
    "#         return self.coef_[\"x\"]\n",
    "\n",
    "\n",
    "# # optR = OptimizedRounder()\n",
    "# # optR.fit(valid_pred, valid_dataset[\"labels\"])\n",
    "# # print(optR.coefficients)\n",
    "\n",
    "# # optimized = optR.predict(valid_pred, optR.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:48.132563Z",
     "iopub.status.busy": "2024-05-18T05:12:48.132353Z",
     "iopub.status.idle": "2024-05-18T05:12:48.136290Z",
     "shell.execute_reply": "2024-05-18T05:12:48.135725Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/cdeotte/deberta-v3-small-starter-cv-0-820-lb-0-800\n",
    "def compute_metrics_for_classification(eval_pred):\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "    qwk = cohen_kappa_score(labels, predictions.argmax(-1), weights=\"quadratic\")\n",
    "    results = {\"qwk\": qwk}\n",
    "    return results\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# def compute_metrics_for_regression(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     mse = mean_squared_error(labels, predictions)\n",
    "#     return {\"mse\": mse}\n",
    "\n",
    "\n",
    "# def compute_metrics_for_regression_opt(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "\n",
    "#     optR = OptimizedRounder()\n",
    "#     optR.fit(predictions, labels)\n",
    "#     optimized = optR.predict(predictions, optR.coefficients)\n",
    "\n",
    "#     qwk = cohen_kappa_score(labels, optimized, weights=\"quadratic\")\n",
    "#     return {\"qwk\": qwk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:48.141404Z",
     "iopub.status.busy": "2024-05-18T05:12:48.140713Z",
     "iopub.status.idle": "2024-05-18T05:12:48.145101Z",
     "shell.execute_reply": "2024-05-18T05:12:48.144325Z"
    }
   },
   "outputs": [],
   "source": [
    "# from torch import Tensor, device\n",
    "\n",
    "\n",
    "# # https://www.kaggle.com/code/gennadylaptev/qwk-loss-for-pytorch/notebook\n",
    "# def kappa_loss(\n",
    "#     p: Tensor, y: Tensor, device_name: device, n_classes: int = 6, eps: float = 1e-10\n",
    "# ) -> Tensor:\n",
    "#     \"\"\"\n",
    "#     QWK loss function as described in https://arxiv.org/pdf/1612.00775.pdf\n",
    "\n",
    "#     Arguments:\n",
    "#         p: a tensor with probability predictions, [batch_size, n_classes],\n",
    "#         y, a tensor with one-hot encoded class labels, [batch_size, n_classes]\n",
    "#     Returns:\n",
    "#         QWK loss\n",
    "#     \"\"\"\n",
    "\n",
    "#     W = np.zeros((n_classes, n_classes))\n",
    "#     for i in range(n_classes):\n",
    "#         for j in range(n_classes):\n",
    "#             W[i, j] = (i - j) ** 2\n",
    "\n",
    "#     W = torch.from_numpy(W.astype(np.float32)).to(device_name)\n",
    "\n",
    "#     O = torch.matmul(y.t(), p)\n",
    "#     E = torch.matmul(y.sum(dim=0).view(-1, 1), p.sum(dim=0).view(1, -1)) / O.sum()\n",
    "\n",
    "#     loss = (W * O).sum() / ((W * E).sum() + eps)\n",
    "\n",
    "#     # Normalize loss from [-1, 1] to [0, 1]\n",
    "#     normalized_loss = (loss + 1) / 2\n",
    "\n",
    "#     return normalized_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:48.148177Z",
     "iopub.status.busy": "2024-05-18T05:12:48.147890Z",
     "iopub.status.idle": "2024-05-18T05:12:48.158651Z",
     "shell.execute_reply": "2024-05-18T05:12:48.157547Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/emiz6413/directly-optimize-quadratic-weighted-kappa-loss/notebook\n",
    "class WeightedKappaLoss(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        weights: str = \"quadratic\",\n",
    "        epsilon: float = 1e-6,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        label_vec = torch.arange(0, num_classes).float()\n",
    "        self.row_label_vec = label_vec.view(1, num_classes)\n",
    "        self.col_label_vec = label_vec.view(num_classes, 1)\n",
    "        row_mat = torch.tile(self.row_label_vec, (num_classes, 1))\n",
    "        col_mat = torch.tile(self.col_label_vec, (1, num_classes))\n",
    "        if weights == \"quadratic\":\n",
    "            self.ops = torch.square\n",
    "        elif weights == \"linear\":\n",
    "            self.ops = torch.abs\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        self.num_classes = num_classes\n",
    "        self.weight_mat = self.ops(col_mat - row_mat)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_true: torch.Tensor, y_pred: torch.Tensor) -> torch.Tensor:\n",
    "        bs = y_true.size(0)\n",
    "\n",
    "        # y_true = torch.nn.functional.one_hot(y_true, self.num_classes)\n",
    "        y_true = y_true.to(device=y_pred.device, dtype=y_pred.dtype)\n",
    "\n",
    "        col_label_vec = self.col_label_vec.clone().to(y_pred.device)\n",
    "        row_label_vec = self.row_label_vec.clone().to(y_pred.device)\n",
    "        weight_mat = self.weight_mat.clone().to(y_pred.device)\n",
    "        cat_labels = torch.matmul(y_true, col_label_vec)\n",
    "        cat_label_mat = torch.tile(cat_labels, (1, self.num_classes))\n",
    "        row_label_mat = torch.tile(row_label_vec, (bs, 1))\n",
    "        weight = self.ops(cat_label_mat - row_label_mat)\n",
    "        numerator = torch.sum(weight * y_pred)\n",
    "\n",
    "        label_dist = torch.sum(y_true, dim=0, keepdim=True)\n",
    "        pred_dist = torch.sum(y_pred, dim=0, keepdim=True)\n",
    "\n",
    "        w_pred_dist = torch.matmul(weight_mat, pred_dist.T)\n",
    "        dominator = torch.sum(torch.matmul(label_dist, w_pred_dist)) / bs\n",
    "\n",
    "        loss = torch.log(numerator / dominator + self.epsilon)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "loss_fn = WeightedKappaLoss(num_classes=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:48.161749Z",
     "iopub.status.busy": "2024-05-18T05:12:48.161393Z",
     "iopub.status.idle": "2024-05-18T05:12:48.167030Z",
     "shell.execute_reply": "2024-05-18T05:12:48.165861Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Convert logits to probabilities\n",
    "        prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "        # One-hot encode labels\n",
    "        one_hot_labels = torch.nn.functional.one_hot(\n",
    "            labels.long(), num_classes=self.model.config.num_labels\n",
    "        )\n",
    "\n",
    "        one_hot_labels = one_hot_labels.float()\n",
    "\n",
    "        # Compute kappa loss\n",
    "        # loss = kappa_loss(prob, one_hot_labels, device_name=prob.device)\n",
    "        loss = loss_fn(y_true=one_hot_labels, y_pred=prob)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:48.169981Z",
     "iopub.status.busy": "2024-05-18T05:12:48.169693Z",
     "iopub.status.idle": "2024-05-18T05:12:50.706377Z",
     "shell.execute_reply": "2024-05-18T05:12:50.693132Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# regression\n",
    "# https://discuss.huggingface.co/t/how-to-set-up-trainer-for-a-regression/12994\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=1)\n",
    "\n",
    "# classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS,\n",
    "    id2label=score2label,\n",
    "    label2id=label2score,\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)\n",
    "\n",
    "# cast labels to float for regression\n",
    "train_test_split_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_test_split_dataset[\"train\"].cast_column(\n",
    "            \"labels\", Value(dtype=\"float\")\n",
    "        ),\n",
    "        \"valid\": train_test_split_dataset[\"valid\"].cast_column(\n",
    "            \"labels\", Value(dtype=\"float\")\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "print(train_test_split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:50.711785Z",
     "iopub.status.busy": "2024-05-18T05:12:50.711057Z",
     "iopub.status.idle": "2024-05-18T05:12:50.718559Z",
     "shell.execute_reply": "2024-05-18T05:12:50.717643Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:50.723085Z",
     "iopub.status.busy": "2024-05-18T05:12:50.722696Z",
     "iopub.status.idle": "2024-05-18T05:12:50.728430Z",
     "shell.execute_reply": "2024-05-18T05:12:50.726756Z"
    }
   },
   "outputs": [],
   "source": [
    "# if not DEBUG:\n",
    "#     assert len(set(train_test_split_dataset[\"train\"][\"labels\"])) == NUM_LABELS\n",
    "#     assert len(set(train_test_split_dataset[\"valid\"][\"labels\"])) == NUM_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:50.733334Z",
     "iopub.status.busy": "2024-05-18T05:12:50.732519Z",
     "iopub.status.idle": "2024-05-18T05:12:50.774103Z",
     "shell.execute_reply": "2024-05-18T05:12:50.773034Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_PATH,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=TRAIN_BS,\n",
    "    gradient_accumulation_steps=GRAD_ACC_NUM,\n",
    "    eval_accumulation_steps=GRAD_ACC_NUM,\n",
    "    per_device_eval_batch_size=EVAL_BS,\n",
    "    num_train_epochs=EPOCH,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=EVAL_STEP,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=SAVE_STEP,\n",
    "    save_total_limit=1,\n",
    "    seed=SEED,\n",
    "    metric_for_best_model=\"qwk\",\n",
    "    # metric_for_best_model=\"mse\",\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine_with_restarts\",\n",
    "    report_to=REPORT_TO,\n",
    "    run_name=EXP_NAME,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_test_split_dataset[\"train\"],\n",
    "#     eval_dataset=train_test_split_dataset[\"valid\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     # compute_metrics=compute_metrics_for_regression,\n",
    "#     # compute_metrics=compute_metrics_for_regression_opt,\n",
    "#     compute_metrics=compute_metrics_for_classification,\n",
    "# )\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_test_split_dataset[\"train\"],\n",
    "    eval_dataset=train_test_split_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    # compute_metrics=compute_metrics_for_regression,\n",
    "    # compute_metrics=compute_metrics_for_regression_opt,\n",
    "    compute_metrics=compute_metrics_for_classification,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-05-18T05:12:50.777879Z",
     "iopub.status.busy": "2024-05-18T05:12:50.777508Z",
     "iopub.status.idle": "2024-05-18T05:12:57.435111Z",
     "shell.execute_reply": "2024-05-18T05:12:57.434083Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 6.69 MiB is free. Process 1682551 has 7.56 GiB memory in use. Process 1980650 has 4.27 GiB memory in use. Process 2002546 has 4.05 GiB memory in use. Of the allocated memory 3.22 GiB is allocated by PyTorch, and 105.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAINING:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# モデルの学習\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# ログの保存に利用したストレージを削除\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrm -rf \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_OUTPUT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/checkpoint-*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py:2266\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2263\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[1;32m   2265\u001b[0m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[0;32m-> 2266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2267\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   2268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   2269\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/optimizer.py:157\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_patched_step_method\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called:\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;66;03m# If the optimizer step was skipped, gradient overflow was detected.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/amp/grad_scaler.py:416\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    414\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 416\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/amp/grad_scaler.py:315\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 315\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/optimizer.py:212\u001b[0m, in \u001b[0;36mpatch_optimizer_step.<locals>.patched_step\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpatched_step\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    211\u001b[0m     accelerated_optimizer\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py:184\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    171\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    174\u001b[0m         group,\n\u001b[1;32m    175\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m         state_steps,\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py:335\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 335\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py:599\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    597\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 599\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[1;32m    602\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 6.69 MiB is free. Process 1682551 has 7.56 GiB memory in use. Process 1980650 has 4.27 GiB memory in use. Process 2002546 has 4.05 GiB memory in use. Of the allocated memory 3.22 GiB is allocated by PyTorch, and 105.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    # モデルの学習\n",
    "    trainer.train()\n",
    "    # ログの保存に利用したストレージを削除\n",
    "    os.system(f\"rm -rf {MODEL_OUTPUT_PATH}/checkpoint-*\")\n",
    "    # モデルの保存\n",
    "    trainer.save_model(MODEL_OUTPUT_PATH)\n",
    "else:\n",
    "    # TRAINED_MODEL_PATHを用いて、学習済のモデルを読み込む\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        TRAINED_MODEL_PATH,\n",
    "        # num_labels=1,\n",
    "        # problem_type=\"regression\",\n",
    "    )\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        \".\",\n",
    "        per_device_eval_batch_size=4,\n",
    "        report_to=\"none\",\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    # trainer = Trainer(\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid_datasetの作成・保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# cls\n",
    "\n",
    "def get_valid_preds(trainer, valid_dataset):\n",
    "    \"\"\"\n",
    "    trainerを用いてvalid_datasetに対する予測を行う\n",
    "    \"\"\"\n",
    "    predictions = trainer.predict(valid_dataset).predictions\n",
    "    preds_final = predictions.argmax(-1)\n",
    "\n",
    "    return preds_final\n",
    "\n",
    "\n",
    "def add_valid_pred(example, idx, valid_pred):\n",
    "    example[\"valid_pred\"] = valid_pred[idx]\n",
    "    return example\n",
    "\n",
    "valid_dataset = train_test_split_dataset[\"valid\"]\n",
    "\n",
    "if TRAINING:\n",
    "    valid_pred = get_valid_preds(trainer, valid_dataset)\n",
    "    valid_pred = [label2score[valid] for valid in valid_pred]\n",
    "    np.save(f\"{MODEL_OUTPUT_PATH}/valid_prediction.npy\", np.array(valid_pred))\n",
    "else:\n",
    "    valid_pred = np.load(f\"{TRAINED_MODEL_PATH}/valid_prediction.npy\")\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    add_valid_pred, with_indices=True, fn_kwargs={\"valid_pred\": valid_pred}\n",
    ")\n",
    "\n",
    "valid_dataset.save_to_disk(f\"{MODEL_OUTPUT_PATH}/valid_dataset\")\n",
    "\n",
    "# # reg\n",
    "# valid_dataset = train_test_split_dataset[\"valid\"]\n",
    "\n",
    "\n",
    "# def add_valid_pred(example, idx, valid_pred):\n",
    "#     example[\"valid_pred\"] = valid_pred[idx]\n",
    "#     return example\n",
    "\n",
    "\n",
    "# valid_pred = trainer.predict(valid_dataset).predictions.flatten()\n",
    "\n",
    "# np.save(f\"{MODEL_OUTPUT_PATH}/valid_prediction.npy\", valid_pred)\n",
    "\n",
    "# valid_dataset = valid_dataset.map(\n",
    "#     add_valid_pred, with_indices=True, fn_kwargs={\"valid_pred\": valid_pred}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy as sp\n",
    "\n",
    "# from functools import partial\n",
    "\n",
    "\n",
    "# # https://qiita.com/kaggle_grandmaster-arai-san/items/d59b2fb7142ec7e270a5#optimizedrounder\n",
    "# class OptimizedRounder(object):\n",
    "#     def __init__(self):\n",
    "#         self.coef_ = 0\n",
    "\n",
    "#     def _kappa_loss(self, coef, X, y):\n",
    "#         X_p = np.copy(X)\n",
    "#         for i, pred in enumerate(X_p):\n",
    "#             if pred < coef[0]:\n",
    "#                 X_p[i] = 1\n",
    "#             elif pred >= coef[0] and pred < coef[1]:\n",
    "#                 X_p[i] = 2\n",
    "#             elif pred >= coef[1] and pred < coef[2]:\n",
    "#                 X_p[i] = 3\n",
    "#             elif pred >= coef[2] and pred < coef[3]:\n",
    "#                 X_p[i] = 4\n",
    "#             elif pred >= coef[3] and pred < coef[4]:\n",
    "#                 X_p[i] = 5\n",
    "#             else:\n",
    "#                 X_p[i] = 6\n",
    "\n",
    "#         ll = cohen_kappa_score(y, X_p, weights=\"quadratic\")\n",
    "#         return -ll\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "#         initial_coef = [1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "#         self.coef_ = sp.optimize.minimize(\n",
    "#             loss_partial, initial_coef, method=\"nelder-mead\"\n",
    "#         )\n",
    "\n",
    "#     def predict(self, X, coef):\n",
    "#         X_p = np.copy(X)\n",
    "#         for i, pred in enumerate(X_p):\n",
    "#             if pred < coef[0]:\n",
    "#                 X_p[i] = 1\n",
    "#             elif pred >= coef[0] and pred < coef[1]:\n",
    "#                 X_p[i] = 2\n",
    "#             elif pred >= coef[1] and pred < coef[2]:\n",
    "#                 X_p[i] = 3\n",
    "#             elif pred >= coef[2] and pred < coef[3]:\n",
    "#                 X_p[i] = 4\n",
    "#             elif pred >= coef[3] and pred < coef[4]:\n",
    "#                 X_p[i] = 5\n",
    "#             else:\n",
    "#                 X_p[i] = 6\n",
    "#         return X_p\n",
    "\n",
    "#     @property\n",
    "#     def coefficients(self):\n",
    "#         return self.coef_[\"x\"]\n",
    "\n",
    "\n",
    "# optR = OptimizedRounder()\n",
    "# optR.fit(valid_pred, valid_dataset[\"labels\"])\n",
    "# print(optR.coefficients)\n",
    "\n",
    "# optimized = optR.predict(valid_pred, optR.coefficients)\n",
    "\n",
    "# np.save(f\"{MODEL_OUTPUT_PATH}/opt_thr.npy\", optR.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # reg\n",
    "# def clip_valid_pred(example):\n",
    "#     # 四捨五入を実施\n",
    "#     example[\"valid_pred\"] = np.clip(example[\"valid_pred\"], 1, 6).round()\n",
    "#     return example\n",
    "\n",
    "\n",
    "# valid_dataset = valid_dataset.map(clip_valid_pred)\n",
    "\n",
    "# cv_score = cohen_kappa_score(\n",
    "#     valid_dataset[\"labels\"], valid_dataset[\"valid_pred\"], weights=\"quadratic\"\n",
    "# )\n",
    "\n",
    "# print(f\"CV Score by round: {cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reg\n",
    "cv_score = cohen_kappa_score(\n",
    "    valid_dataset[\"score\"], valid_dataset[\"valid_pred\"], weights=\"quadratic\"\n",
    ")\n",
    "\n",
    "print(f\"CV Score: {cv_score}\")\n",
    "\n",
    "# # cls\n",
    "# cv_score = cohen_kappa_score(valid_dataset[\"labels\"], optimized, weights=\"quadratic\")\n",
    "\n",
    "# print(f\"CV Score by NelderMead: {cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output_textを保存\n",
    "with open(f\"{MODEL_OUTPUT_PATH}/cv_score.txt\", \"w\") as f:\n",
    "    f.write(str(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    valid_dataset[\"score\"],\n",
    "    valid_dataset[\"valid_pred\"],\n",
    "    labels=[x for x in range(1, 7)],\n",
    ")\n",
    "\n",
    "draw_cm = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm, display_labels=[x for x in range(1, 7)]\n",
    ")\n",
    "\n",
    "draw_cm.plot()\n",
    "plt.savefig(f\"{MODEL_OUTPUT_PATH}/confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWSへのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3へのアップロード\n",
    "if not DEBUG and UPLOAD_DATA_TO_S3:\n",
    "    # uninstall\n",
    "    !sudo rm /usr/bin/aws\n",
    "    !sudo rm /usr/bin/aws_completer\n",
    "    !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "    # install\n",
    "    !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "    !unzip -o -qq awscliv2.zip\n",
    "    !sudo ./aws/install --update\n",
    "\n",
    "    # upload\n",
    "    output_name = MODEL_OUTPUT_PATH.split(\"/\")[-1]\n",
    "    os.system(\n",
    "        f\"aws s3 cp --recursive {MODEL_OUTPUT_PATH} s3://automated-essay-scoring/trained_model/{output_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINED_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ダウンロード（参考）\n",
    "# !sudo rm /usr/bin/aws\n",
    "# !sudo rm /usr/bin/aws_completer\n",
    "# !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "# !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "# !unzip -o -qq awscliv2.zip\n",
    "# !sudo ./aws/install --update\n",
    "\n",
    "# !aws s3 cp --recursive s3://automated-essay-scoring/trained_model/e012-cls-with-qwkloss/ /notebooks/automated_essay_scoring/trained_models/e012-cls-with-qwkloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Datasetへのupload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not DEBUG and UPLOAD_DATA_TO_KAGGLE:\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    def dataset_create_new(dataset_name: str, upload_dir: str):\n",
    "        # if \"_\" in dataset_name:\n",
    "        #     raise ValueError(\"datasetの名称に_の使用は禁止です\")\n",
    "        dataset_metadata = {}\n",
    "        dataset_metadata[\"id\"] = f\"sinchir0/{dataset_name}\"\n",
    "        dataset_metadata[\"licenses\"] = [{\"name\": \"CC0-1.0\"}]\n",
    "        dataset_metadata[\"title\"] = dataset_name\n",
    "        with open(os.path.join(upload_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "            json.dump(dataset_metadata, f, indent=4)\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode=\"tar\")\n",
    "\n",
    "    print(f\"Create Dataset name:{DATASET_NAME}, output_dir:{MODEL_OUTPUT_PATH}\")\n",
    "    dataset_create_new(dataset_name=DATASET_NAME, upload_dir=MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ローカルからのデータの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG and (UPLOAD_DATA_TO_S3 or UPLOAD_DATA_TO_KAGGLE):\n",
    "    # ローカルからは削除\n",
    "    os.system(f\"rm -rf {MODEL_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"finish Notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1040178f995d4b69a28a47872de3f1db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1485ac2d0cdf4de0800a8b15a8bc2a8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_940483944c6242a5a94e4e7b18151b5c",
        "IPY_MODEL_938267731fca4f48b51e506859bf1d06",
        "IPY_MODEL_15233866307d4ce9ad17fb22c5ae994a"
       ],
       "layout": "IPY_MODEL_57034562323b4380b8af90940df2cf90",
       "tabbable": null,
       "tooltip": null
      }
     },
     "15233866307d4ce9ad17fb22c5ae994a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6379522039c448a896e640f0834e1503",
       "placeholder": "​",
       "style": "IPY_MODEL_56eea7c3be13449fb1ee64efcc6a38d9",
       "tabbable": null,
       "tooltip": null,
       "value": " 5769/5769 [00:00&lt;00:00, 11435.38 examples/s]"
      }
     },
     "17dca883ed3b417bb7958161581b357a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "25891ddaab9f454c9c499a93994c3050": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "32dd623e993e4f2f96bba337988cc63e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_17dca883ed3b417bb7958161581b357a",
       "max": 5769,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1040178f995d4b69a28a47872de3f1db",
       "tabbable": null,
       "tooltip": null,
       "value": 5769
      }
     },
     "448b1cf58a6541b39b04ec7fb90fe58c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4539e01ec017451f99691fc5eca5b069": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50b071b1baed425c9f5c0f57cd283483": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "56eea7c3be13449fb1ee64efcc6a38d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "57034562323b4380b8af90940df2cf90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6379522039c448a896e640f0834e1503": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7fe0e6fe5c644cf8ae98945068a0d386": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dced4483bd174eb797bee80c97adb5c9",
       "placeholder": "​",
       "style": "IPY_MODEL_448b1cf58a6541b39b04ec7fb90fe58c",
       "tabbable": null,
       "tooltip": null,
       "value": "Saving the dataset (1/1 shards): 100%"
      }
     },
     "83a20a05f6d04c2d8843a83358082498": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "938267731fca4f48b51e506859bf1d06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_25891ddaab9f454c9c499a93994c3050",
       "max": 5769,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_83a20a05f6d04c2d8843a83358082498",
       "tabbable": null,
       "tooltip": null,
       "value": 5769
      }
     },
     "940483944c6242a5a94e4e7b18151b5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b8f7243d7ca84e21971898c29a1edffe",
       "placeholder": "​",
       "style": "IPY_MODEL_50b071b1baed425c9f5c0f57cd283483",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "b8f7243d7ca84e21971898c29a1edffe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d24d10b4338546838a3a7247cc2d4039": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7fe0e6fe5c644cf8ae98945068a0d386",
        "IPY_MODEL_32dd623e993e4f2f96bba337988cc63e",
        "IPY_MODEL_ecd4a27c48bc4dcbabd5c75fd6637594"
       ],
       "layout": "IPY_MODEL_4539e01ec017451f99691fc5eca5b069",
       "tabbable": null,
       "tooltip": null
      }
     },
     "dced4483bd174eb797bee80c97adb5c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e92266afbcc84d1ba5b4652f5153e619": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ecd4a27c48bc4dcbabd5c75fd6637594": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e92266afbcc84d1ba5b4652f5153e619",
       "placeholder": "​",
       "style": "IPY_MODEL_ee5fd0b6deb5446e9f037cd51faa5dd1",
       "tabbable": null,
       "tooltip": null,
       "value": " 5769/5769 [00:00&lt;00:00, 151952.65 examples/s]"
      }
     },
     "ee5fd0b6deb5446e9f037cd51faa5dd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
